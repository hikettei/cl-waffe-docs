<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <title>
  Using Tensor &ndash; cl-waffe
</title>
    <link rel="stylesheet" href="static/style.css"/>
    
  <link rel="stylesheet" href="static/highlight.css"/>
  <script src="static/highlight.js"></script>
  <style>
   /* Highlight the current top-level TOC item, and hide the TOC of all other items */

   .toc a[data-node="using-tensor"] {
       /*color: #AD3108;*/
   }

   .toc ol {
       display: none;
   }

   .toc li a[data-node="using-tensor"] {
       font-weight: bold;
   }

   .toc li a[data-node="using-tensor"] + ol {
       display: block;
   }

   .toc li a[data-node="using-tensor"] + ol li {
       margin-left: 10px;
   }
  </style>

  </head>
  <body>
    
  <h1 class="doc-title">cl-waffe</h1>
  <article id="article" data-section="using-tensor">
    <aside>
      <ol class="toc"><li><a href="overview.html" data-node="overview">Overview</a><ol><li><a href="overview.html#welcome-to-cl-waffe!" data-node="welcome-to-cl-waffe!">Welcome to cl-waffe!</a></li><li><a href="overview.html#problems" data-node="problems">Problems</a></li><li><a href="overview.html#sections" data-node="sections">Sections</a></li><li><a href="overview.html#pull-requests" data-node="pull-requests">Pull Requests</a></li><li><a href="overview.html#contacts" data-node="contacts">Contacts</a></li><li><a href="overview.html#lla-setting" data-node="lla-setting">LLA Setting</a></li><li><a href="overview.html#when-memory-exhausted" data-node="when-memory-exhausted">When Memory Exhausted</a></li></ol></li><li><a href="mnist-tutorial.html" data-node="mnist-tutorial">MNIST Tutorial</a><ol><li><a href="mnist-tutorial.html#first" data-node="first">First</a></li><li><a href="mnist-tutorial.html#define-your-model" data-node="define-your-model">Define Your Model</a></li><li><a href="mnist-tutorial.html#define-your-dataset" data-node="define-your-dataset">Define Your Dataset</a><ol><li><a href="cl-waffe's-dataset--waffedataset.html" data-node="cl-waffe's-dataset--waffedataset">cl-waffe's Dataset: WaffeDataSet</a></li></ol></li><li><a href="mnist-tutorial.html#train-your-model" data-node="train-your-model">Train Your Model</a></li></ol></li><li><a href="using-tensor.html" data-node="using-tensor">Using Tensor</a><ol><li><a href="using-tensor.html#basic-tensor-operations" data-node="basic-tensor-operations">Basic Tensor Operations</a></li><li><a href="using-tensor.html#building-computation-nodes" data-node="building-computation-nodes">Building Computation Nodes</a><ol><li><a href="using-tensor.html#construct-tensors" data-node="construct-tensors">Construct Tensors</a><ol><li><a href="using-tensor.html#constants" data-node="constants">Constants</a></li><li><a href="using-tensor.html#parameter-tensors" data-node="parameter-tensors">Parameter Tensors</a></li><li><a href="using-tensor.html#sysconst" data-node="sysconst">Sysconst</a></li></ol></li></ol></li><li><a href="using-tensor.html#accessing-tensor" data-node="accessing-tensor">Accessing Tensor</a></li><li><a href="using-tensor.html#backward-and-predicting-mode" data-node="backward-and-predicting-mode">backward and predicting mode</a></li><li><a href="using-tensor.html#calling-forward-of-cl-waffe's-objects" data-node="calling-forward-of-cl-waffe's-objects">Calling Forward of cl-waffe's objects</a></li><li><a href="using-tensor.html#displaying-tensors" data-node="displaying-tensors">Displaying Tensors</a></li><li><a href="using-tensor.html#types" data-node="types">Types</a></li><li><a href="using-tensor.html#lazy-evaluation" data-node="lazy-evaluation">Lazy evaluation</a></li><li><a href="using-tensor.html#broadcasting" data-node="broadcasting">Broadcasting</a></li><li><a href="using-tensor.html#jit" data-node="jit">JIT</a></li><li><a href="using-tensor.html#tracing" data-node="tracing">Tracing</a></li><li><a href="using-tensor.html#compute-tensors-in-a-destructive-way" data-node="compute-tensors-in-a-destructive-way">Compute tensors in a destructive way</a><ol><li><a href="using-tensor.html#creating-destructive-operations" data-node="creating-destructive-operations">Creating Destructive Operations</a></li></ol></li><li><a href="using-tensor.html#logging" data-node="logging">Logging</a></li><li><a href="using-tensor.html#backends" data-node="backends">Backends</a></li></ol></li><li><a href="extend-library.html" data-node="extend-library">Extend library</a><ol><li><a href="defmodel.html" data-node="defmodel">defmodel</a><ol><li><a href="initialize-and-call-model.html" data-node="initialize-and-call-model">Initialize and call model</a></li><li><a href="clos-style.html" data-node="clos-style">CLOS Style</a></li></ol></li><li><a href="deftrainer.html" data-node="deftrainer">deftrainer</a></li><li><a href="defoptimizer.html" data-node="defoptimizer">defoptimizer</a></li><li><a href="defnode.html" data-node="defnode">defnode</a></li><li><a href="defdataset.html" data-node="defdataset">defdataset</a></li></ol></li><li><a href="cl-waffe.html" data-node="cl-waffe">cl-waffe</a><ol><li><a href="package--cl-waffe.html" data-node="package--cl-waffe">Package :cl-waffe</a></li><li><a href="0-sections.html" data-node="0-sections">Sections</a></li><li><a href="model-and-node.html" data-node="model-and-node">Model And Node</a></li><li><a href="1-defmodel.html" data-node="1-defmodel">defmodel</a></li><li><a href="2-defnode.html" data-node="2-defnode">defnode</a></li><li><a href="trainer.html" data-node="trainer">Trainer</a></li><li><a href="3-deftrainer.html" data-node="3-deftrainer">deftrainer</a></li><li><a href="datasets.html" data-node="datasets">Datasets</a></li><li><a href="4-defdataset.html" data-node="4-defdataset">defdataset</a></li><li><a href="optimizer.html" data-node="optimizer">optimizer</a></li><li><a href="5-defoptimizer.html" data-node="5-defoptimizer">defoptimizer</a></li><li><a href="documentation-template.html" data-node="documentation-template">Documentation Template</a></li></ol></li><li><a href="cl-waffe.nn.html" data-node="cl-waffe.nn">cl-waffe.nn</a><ol><li><a href="exported.html" data-node="exported">Exported</a></li></ol></li><li><a href="cl-waffe.optimizers.html" data-node="cl-waffe.optimizers">cl-waffe.optimizers</a><ol><li><a href="6-sections.html" data-node="6-sections">Sections</a></li><li><a href="training-models-with-optimizer.html" data-node="training-models-with-optimizer">Training Models With Optimizer</a></li></ol></li><li><a href="cl-waffe.io.html" data-node="cl-waffe.io">cl-waffe.io</a><ol><li><a href="7-exported.html" data-node="7-exported">Exported</a></li></ol></li><li><a href="cl-waffe.caches.html" data-node="cl-waffe.caches">cl-waffe.caches</a><ol><li><a href="8-exported.html" data-node="8-exported">Exported</a></li></ol></li><li><a href="operators.html" data-node="operators">Operators</a><ol><li><a href="!shape.html" data-node="!shape">!shape</a></li><li><a href="!dims.html" data-node="!dims">!dims</a></li><li><a href="!size.html" data-node="!size">!size</a></li><li><a href="!zeros.html" data-node="!zeros">!zeros</a></li><li><a href="!ones.html" data-node="!ones">!ones</a></li><li><a href="!fill.html" data-node="!fill">!fill</a></li><li><a href="!arange.html" data-node="!arange">!arange</a><ol><li><a href="(-!arange-stop-).html" data-node="(-!arange-stop-)">(!arange stop)</a></li><li><a href="(-!arange-start-stop-).html" data-node="(-!arange-start-stop-)">(!arange start stop)</a></li><li><a href="(-!arange-start-stop-step-).html" data-node="(-!arange-start-stop-step-)">(!arange start stop step)</a></li></ol></li><li><a href="!random.html" data-node="!random">!random</a><ol><li><a href="when-limit=fixnum.html" data-node="when-limit=fixnum">When limit=fixnum</a></li><li><a href="when-limit=single-float.html" data-node="when-limit=single-float">When limit=single-float</a></li><li><a href="when-limit=-(-cons-single-float1-single-float2-).html" data-node="when-limit=-(-cons-single-float1-single-float2-)">When limit=(cons single-float1 single-float2)</a></li></ol></li><li><a href="!random-with.html" data-node="!random-with">!random-with</a></li><li><a href="!init-with.html" data-node="!init-with">!init-with</a></li><li><a href="!normal.html" data-node="!normal">!normal</a></li><li><a href="!randn.html" data-node="!randn">!randn</a></li><li><a href="!beta.html" data-node="!beta">!beta</a></li><li><a href="!gamma.html" data-node="!gamma">!gamma</a></li><li><a href="!chisquare.html" data-node="!chisquare">!chisquare</a></li><li><a href="!bernoulli.html" data-node="!bernoulli">!bernoulli</a></li><li><a href="!binomial.html" data-node="!binomial">!binomial</a></li><li><a href="9-!shape.html" data-node="9-!shape">!shape</a></li><li><a href="10-!dims.html" data-node="10-!dims">!dims</a></li><li><a href="11-!size.html" data-node="11-!size">!size</a></li><li><a href="!zeros-like.html" data-node="!zeros-like">!zeros-like</a></li><li><a href="!ones-like.html" data-node="!ones-like">!ones-like</a></li><li><a href="!full-like.html" data-node="!full-like">!full-like</a></li><li><a href="!add.html" data-node="!add">!add</a><ol><li><a href="examples.html" data-node="examples">Examples</a></li></ol></li><li><a href="!sub.html" data-node="!sub">!sub</a><ol><li><a href="12-examples.html" data-node="12-examples">Examples</a></li></ol></li><li><a href="!mul.html" data-node="!mul">!mul</a><ol><li><a href="13-examples.html" data-node="13-examples">Examples</a></li></ol></li><li><a href="!div.html" data-node="!div">!div</a><ol><li><a href="14-examples.html" data-node="14-examples">Examples</a></li></ol></li><li><a href="!dot.html" data-node="!dot">!dot</a><ol><li><a href="example.html" data-node="example">Example</a></li></ol></li><li><a href="!sum.html" data-node="!sum">!sum</a><ol><li><a href="arguments.html" data-node="arguments">arguments</a></li><li><a href="15-example.html" data-node="15-example">Example</a></li></ol></li><li><a href="!mean.html" data-node="!mean">!mean</a><ol><li><a href="16-example.html" data-node="16-example">Example</a></li></ol></li><li><a href="!exp.html" data-node="!exp">!exp</a><ol><li><a href="17-example.html" data-node="17-example">Example</a></li></ol></li><li><a href="!pow.html" data-node="!pow">!pow</a><ol><li><a href="18-example.html" data-node="18-example">Example</a></li></ol></li><li><a href="!sqrt.html" data-node="!sqrt">!sqrt</a><ol><li><a href="19-example.html" data-node="19-example">Example</a></li></ol></li><li><a href="!log.html" data-node="!log">!log</a><ol><li><a href="20-example.html" data-node="20-example">Example</a></li></ol></li><li><a href="!sin.html" data-node="!sin">!sin</a><ol><li><a href="21-example.html" data-node="21-example">Example</a></li></ol></li><li><a href="!cos.html" data-node="!cos">!cos</a><ol><li><a href="22-example.html" data-node="22-example">Example</a></li></ol></li><li><a href="!tan.html" data-node="!tan">!tan</a><ol><li><a href="23-example.html" data-node="23-example">Example</a></li></ol></li><li><a href="!asin.html" data-node="!asin">!asin</a></li><li><a href="!acos.html" data-node="!acos">!acos</a></li><li><a href="!atan.html" data-node="!atan">!atan</a></li><li><a href="!sinh.html" data-node="!sinh">!sinh</a><ol><li><a href="24-example.html" data-node="24-example">Example</a></li></ol></li><li><a href="!cosh.html" data-node="!cosh">!cosh</a><ol><li><a href="25-example.html" data-node="25-example">Example</a></li></ol></li><li><a href="!tanh.html" data-node="!tanh">!tanh</a></li><li><a href="!asinh.html" data-node="!asinh">!asinh</a></li><li><a href="!acosh.html" data-node="!acosh">!acosh</a></li><li><a href="!atanh.html" data-node="!atanh">!atanh</a></li><li><a href="!matmul.html" data-node="!matmul">!matmul</a></li><li><a href="!concatenate.html" data-node="!concatenate">!concatenate</a><ol><li><a href="26-example.html" data-node="26-example">Example</a></li></ol></li><li><a href="!stack.html" data-node="!stack">!stack</a><ol><li><a href="27-example.html" data-node="27-example">Example</a></li></ol></li><li><a href="!split.html" data-node="!split">!split</a><ol><li><a href="28-example.html" data-node="28-example">Example</a></li></ol></li><li><a href="!vstack.html" data-node="!vstack">!vstack</a></li><li><a href="!hstack.html" data-node="!hstack">!hstack</a></li><li><a href="!unsqueeze.html" data-node="!unsqueeze">!unsqueeze</a><ol><li><a href="29-example.html" data-node="29-example">Example</a></li></ol></li><li><a href="!squeeze.html" data-node="!squeeze">!squeeze</a><ol><li><a href="30-example.html" data-node="30-example">Example</a></li></ol></li><li><a href="!transpose.html" data-node="!transpose">!transpose</a><ol><li><a href="31-example.html" data-node="31-example">Example</a></li></ol></li><li><a href="!transpose1.html" data-node="!transpose1">!transpose1</a><ol><li><a href="32-example.html" data-node="32-example">Example</a></li></ol></li><li><a href="!repeats.html" data-node="!repeats">!repeats</a><ol><li><a href="33-example.html" data-node="33-example">Example</a></li></ol></li><li><a href="!reshape.html" data-node="!reshape">!reshape</a><ol><li><a href="34-example.html" data-node="34-example">Example</a></li></ol></li><li><a href="!abs.html" data-node="!abs">!abs</a></li><li><a href="!where.html" data-node="!where">!where</a><ol><li><a href="35-example.html" data-node="35-example">Example</a></li></ol></li><li><a href="!index.html" data-node="!index">!index</a></li><li><a href="!filter.html" data-node="!filter">!filter</a></li><li><a href="!argmax.html" data-node="!argmax">!argmax</a><ol><li><a href="36-example.html" data-node="36-example">Example</a></li></ol></li><li><a href="!argmin.html" data-node="!argmin">!argmin</a><ol><li><a href="37-example.html" data-node="37-example">Example</a></li></ol></li><li><a href="!<=.html" data-node="!<=">!&lt;=</a></li><li><a href="!>=.html" data-node="!>=">!&gt;=</a></li><li><a href="!einsum.html" data-node="!einsum">!einsum</a></li><li><a href="!ravel.html" data-node="!ravel">!ravel</a></li><li><a href="!flatten.html" data-node="!flatten">!flatten</a></li><li><a href="!aref.html" data-node="!aref">!aref</a></li><li><a href="!dotensors.html" data-node="!dotensors">!dotensors</a></li><li><a href="!set-batch.html" data-node="!set-batch">!set-batch</a></li><li><a href="!softmax.html" data-node="!softmax">!softmax</a></li><li><a href="!sigmoid.html" data-node="!sigmoid">!sigmoid</a></li><li><a href="!relu.html" data-node="!relu">!relu</a></li><li><a href="!gelu.html" data-node="!gelu">!gelu</a></li><li><a href="!leakey-relu.html" data-node="!leakey-relu">!leakey-relu</a></li><li><a href="!swish.html" data-node="!swish">!swish</a></li></ol></li><li><a href="neural-networks.html" data-node="neural-networks">Neural Networks</a><ol><li><a href="model-list.html" data-node="model-list">model-list</a><ol><li><a href="parameters.html" data-node="parameters">Parameters</a></li><li><a href="forward.html" data-node="forward">Forward</a></li><li><a href="38-example.html" data-node="38-example">Example</a></li></ol></li><li><a href="linearlayer.html" data-node="linearlayer">Linearlayer</a><ol><li><a href="39-parameters.html" data-node="39-parameters">Parameters</a></li><li><a href="shape.html" data-node="shape">Shape</a></li><li><a href="40-forward.html" data-node="40-forward">Forward</a></li><li><a href="41-example.html" data-node="41-example">Example</a></li></ol></li><li><a href="denselayer.html" data-node="denselayer">DenseLayer</a><ol><li><a href="42-parameters.html" data-node="42-parameters">Parameters</a></li><li><a href="43-shape.html" data-node="43-shape">Shape</a></li><li><a href="44-forward.html" data-node="44-forward">Forward</a></li><li><a href="45-example.html" data-node="45-example">Example</a></li></ol></li><li><a href="dropout.html" data-node="dropout">Dropout</a><ol><li><a href="46-parameters.html" data-node="46-parameters">Parameters</a></li><li><a href="47-shape.html" data-node="47-shape">Shape</a></li><li><a href="48-forward.html" data-node="48-forward">Forward</a></li></ol></li><li><a href="batchnorm2d.html" data-node="batchnorm2d">BatchNorm2d</a><ol><li><a href="49-parameters.html" data-node="49-parameters">Parameters</a></li><li><a href="50-shape.html" data-node="50-shape">Shape</a></li><li><a href="51-example.html" data-node="51-example">Example</a></li></ol></li><li><a href="layernorm.html" data-node="layernorm">LayerNorm</a></li><li><a href="embedding.html" data-node="embedding">Embedding</a><ol><li><a href="parameter.html" data-node="parameter">Parameter</a></li><li><a href="52-shape.html" data-node="52-shape">Shape</a></li><li><a href="53-example.html" data-node="53-example">Example</a></li></ol></li><li><a href="rnn.html" data-node="rnn">RNN</a><ol><li><a href="54-parameters.html" data-node="54-parameters">Parameters</a></li><li><a href="55-shape.html" data-node="55-shape">Shape</a></li><li><a href="56-example.html" data-node="56-example">Example</a></li></ol></li><li><a href="lstm.html" data-node="lstm">LSTM</a></li><li><a href="gru.html" data-node="gru">GRU</a></li><li><a href="maxpooling.html" data-node="maxpooling">MaxPooling</a></li><li><a href="avgpooling.html" data-node="avgpooling">AvgPooling</a></li><li><a href="conv1d.html" data-node="conv1d">Conv1D</a></li><li><a href="conv2d.html" data-node="conv2d">Conv2D</a></li><li><a href="transformer.html" data-node="transformer">Transformer</a></li><li><a href="transformerencoderlayer.html" data-node="transformerencoderlayer">TransformerEncoderLayer</a></li><li><a href="transformerdecoderlayer.html" data-node="transformerdecoderlayer">TransformerDecoderLayer</a></li><li><a href="crossentropy.html" data-node="crossentropy">CrossEntropy</a></li><li><a href="softmaxcrossentropy.html" data-node="softmaxcrossentropy">SoftMaxCrossEntropy</a></li><li><a href="mse.html" data-node="mse">MSE</a></li><li><a href="l1norm.html" data-node="l1norm">L1Norm</a></li><li><a href="l2norm.html" data-node="l2norm">L2Norm</a></li><li><a href="binarycrossentropy.html" data-node="binarycrossentropy">BinaryCrossEntropy</a></li><li><a href="kldivloss.html" data-node="kldivloss">KLdivLoss</a></li><li><a href="cosinesimilarity.html" data-node="cosinesimilarity">CosineSimilarity</a></li></ol></li><li><a href="optimizers.html" data-node="optimizers">Optimizers</a><ol><li><a href="sgd.html" data-node="sgd">SGD</a><ol><li><a href="cl-waffe's-optimizer--sgd.html" data-node="cl-waffe's-optimizer--sgd">cl-waffe's Optimizer: SGD</a></li></ol></li><li><a href="momentum.html" data-node="momentum">Momentum</a><ol><li><a href="cl-waffe's-optimizer--momentum.html" data-node="cl-waffe's-optimizer--momentum">cl-waffe's Optimizer: Momentum</a></li></ol></li><li><a href="adagrad.html" data-node="adagrad">AdaGrad</a><ol><li><a href="cl-waffe's-optimizer--adagrad.html" data-node="cl-waffe's-optimizer--adagrad">cl-waffe's Optimizer: AdaGrad</a></li></ol></li><li><a href="rmsprop.html" data-node="rmsprop">RMSProp</a><ol><li><a href="cl-waffe's-optimizer--rmsprop.html" data-node="cl-waffe's-optimizer--rmsprop">cl-waffe's Optimizer: RMSProp</a></li></ol></li><li><a href="adam.html" data-node="adam">Adam</a><ol><li><a href="cl-waffe's-optimizer--adam.html" data-node="cl-waffe's-optimizer--adam">cl-waffe's Optimizer: Adam</a></li></ol></li><li><a href="adamw.html" data-node="adamw">AdamW</a></li><li><a href="radam.html" data-node="radam">RAdam</a></li></ol></li></ol>
    </aside>
    <main class="codex-section">
      <header>
        <h2 class="section-title">Using Tensor</h2>
      </header>
      <div class="content">
        <h1 id="basic-tensor-operations">Basic Tensor Operations</h1><p>There is a section here that explains the basics of tensors.
</p><h1 id="building-computation-nodes">Building Computation Nodes</h1><p>Generally, the structure <code class="codex-param">WaffeTensor</code> is used in order to use waffe's APIs, building computation nodes.</p><p>WaffeTensor's slot can store the following data structures, being accessed by (data tensor).</p><ol><li>fixnum</li><li>float</li><li>boolean</li><li>cons</li><li>simple-array (Automatically converted to mgl-mat:mat)</li><li>mgl-mat:mat</li><li>ratio (Automatically coerced to single-float)</li></ol><p>Internally, the matrix of WaffeTensor is a just mgl-mat, depending on it for the most part. (that is, what mgl-mat to cl-waffe is what Numpy to Chainer.)</p><p>So it is highly recommended to check out <a href="https://github.com/melisgl/mgl-mat.git">mgl-mat's official repository</a> before using cl-waffe.</p><h2 id="construct-tensors">Construct Tensors</h2><p>There's three ways to create tensor depending on its purpose.</p><h3 id="constants">Constants</h3><p>Constant is used when <b>no gradient</b> is required, being created with a function (const value).</p><pre><code class="lisp">(setq a (const 1.0))
;#Const(1.0)

; Using cl-waffe's APIs.
(!add a (const 2.0))
;#Const(3.0)

; Initializes a tensor with sampiling beta distribution.
(!beta `(10 10) 5.0 1.0)
;#Const(((0.866... 0.801... ~ 0.836... 1.0)        
;                 ...
;        (0.826... 1.0 ~ 1.0 0.835...)) :mgl t :shape (10 10))
</code></pre><p>
</p><h3 id="parameter-tensors">Parameter Tensors</h3><p>Parameter tensors is used when <b>gradient</b> is required, being created with a function (tensor value) or macro (parameter const).</p><p>Created tensors will be required gradients, they will be created with a function (backward out), being accessed by (grad tensor).</p><p>In each training step, we have to reset their gradients. (zero-grad) which provided by <code class="codex-param">deftrainer</code> will be useful.</p><pre><code class="lisp">(setq a (tensor 5.0))
(setq b (tensor 3.0))
(setq c (tensor 3.0))

(setq z (!add (!mul a b) c)) ; using cl-waffe's APIs will produce computation nodes.
;#Const(18.0)
(print (cl-waffe::waffetensor-state z)) ; They're stored in its state.
; [Node : ADDTENSOR]
(print (cl-waffe::waffetensor-variables z)) ; Also it contains infomations about nodes.
; (#Const(15.0) #Parameter{3.0 :device :MGL :backward NIL})
(backward z)
; NIL

(grad a)
; 3.0
(grad b)
; 5.0
(grad c)
; 1.0
</code></pre><p>Also, parameter tensors can be created like:</p><pre><code class="lisp">(setq a (parameter (!randn `(10 10))))
;#Parameter{((-1.27... 2.076... ~ 2.816... 1.285...)            
;                         ...
;            (0.837... -0.62... ~ 1.735... -0.08...)) :mgl t :shape (10 10) :device :MGL :backward NIL}
</code></pre><p>Let's check the example in the case of defining a Simple LinearLayer.</p><p>Optimizers defined by a macro <code class="codex-param">defoptimizer</code> can track the model's parameters and update them depending on their style.</p><p>Optimizers will be accesed through deftrainer.</p><pre><code class="lisp">(defmodel LinearLayer (in-features out-features &amp;optional (bias T))
  :parameters ((weight
		(parameter (!mul 0.01 (!randn `(,in-features ,out-features))))
		:type waffetensor)
	      (bias (if bias
			(parameter (!zeros `(1 ,out-features)))
			nil)))
  :forward ((x)
	    (cl-waffe.nn:linear x (self weight)(self bias))))

(deftrainer ExampleTrainer ()
  :model          (LinearLayer 10 3)
  :optimizer      cl-waffe.optimizers:Adam
  :optimizer-args (:lr lr)
  :step-model ((x y)
	       (zero-grad)
	       (let ((out (cl-waffe.nn:softmax-cross-entropy (call (self model) x) y)))
		 (backward out)
		 (update) ; calling trainer's optimizers.
		 out))
 :predict ((x)(call (model) x)))
</code></pre><p>
</p><h3 id="sysconst">Sysconst</h3><p>Sysconst is used to store temporary data during the calculation process.</p><p>In a macro <code class="codex-param">defnode</code>, in each process returning a result, using sysconst is a little faster ways than creating constants with (const tensor)</p><pre><code class="lisp">(defnode ExampleAddNode nil
    :forward ((x y)
              (sysconst ; Tensors created with sysconst will be cached well.
	         (+ (data x)(data y))))
    :backward ((dy)(list dy dy)))

</code></pre><p>
</p><p>
</p><p>
</p><h1 id="accessing-tensor">Accessing Tensor</h1><p>
<div class="codex-doc-node codex-operator codex-function"><code class="codex-name">data</code><code class="codex-lambda-list">(tensor)</code><div class="codex-docstring"><p>Access tensor's data. This won't be copied.</p><p>When tensor's data is lazy evaluted, this function behave following:
</p><ol><li>When tensor is transposed and lazy evaluted, directly returns function object for speed.</li><li> When tensor is cached and lazy evaluted, returns mat object.</li></ol><dl><dt>Input</dt><dd>WaffeTensor</dd><dt>Output</dt><dd>mgl-mat:mat, or waffetensorcontentdata</dd></dl><p>when (data tensor) is a function and is:</p><dl><dt>cached mat</dt><dd>Return mgl-mat, this do not make copy</dd><dt>lazy-evaluation or transposed</dt><dd>Return function itself</dd></dl><p>Note: this function is setfable and inlined</p></div></div>
<div class="codex-doc-node codex-operator codex-function"><code class="codex-name">value</code><code class="codex-lambda-list">(tensor &amp;key (ignore-transpose nil))</code><div class="codex-docstring"><p>Access tensor's data, but if tensor is lazy-evaluated, eval them.</p><p>Note: this is not setfable</p></div></div>
<div class="codex-doc-node codex-operator codex-macro"><code class="codex-name">detach</code><code class="codex-lambda-list">(tensor)</code><div class="codex-docstring"><p>Create a Const with all information except data and backend erased.</p><p>This macro expanded to <code>(const (data tensor))</code>.</p><p>Note: this macro doesn't clone data itself.</p><p>Example:
</p><pre><code class="lisp">(setq a (parameter (!randn `(10 10))))
;#Parameter{((0.062... 0.716... ~ 0.088... 0.692...)            
;                         ...
;            (0.458... 0.194... ~ 0.902... 0.480...)) :mgl t :shape (10 10) :device :MGL :backward NIL}
(detach a)
;#Const(((0.062... 0.716... ~ 0.088... 0.692...)        
;                 ...
;        (0.458... 0.194... ~ 0.902... 0.480...)) :mgl t :shape (10 10))
</code></pre></div></div>

</p><h1 id="backward-and-predicting-mode">backward and predicting mode</h1>

<div class="codex-doc-node codex-operator codex-macro"><code class="codex-name">with-no-grad</code><code class="codex-lambda-list">(&amp;body body)</code><div class="codex-docstring"><p>This macro is used in order to implict that codes below is ignored:
save-for-backward, creating new node object, using backward and processes for it.</p><p>For tasks in which grads are not required, using it helps better performance.</p><pre><code class="lisp">(with-no-grad
  (call (model) x))
</code></pre></div></div>
<div class="codex-doc-node codex-variable"><code class="codex-name">*no-grad*</code><div class="codex-docstring">When t, some node will be ignored. see references below for details. default: nil</div></div>
<div class="codex-doc-node codex-operator codex-function"><code class="codex-name">backward</code><code class="codex-lambda-list">(tensor)</code><div class="codex-docstring"><p>Compute back propagation by traversing the Tensor's computation node.</p><p>The parameters of the model defined by (tensor) or to which (Parameter tensor) is applied, store the gradient in grad slot.</p><p>Note that: tensor must be the shape of `(1) or single value. Otherwise an error occurs.</p><p>In the process calculating backward, new backwards won't be created. (*no-grad* automatically becomes t)</p><dl><dt>Input</dt><dd>WaffeTensor</dd><dt>Output</dt><dd>NIL</dd></dl></div></div>

<h1 id="calling-forward-of-cl-waffe's-objects">Calling Forward of cl-waffe's objects</h1>

<div class="codex-doc-node codex-operator codex-function"><code class="codex-name">call</code><code class="codex-lambda-list">(model &amp;rest args)</code><div class="codex-docstring"><p>Calls the forward steps which defined in: defnode, defmodel, defoptimizer.</p><p>All forward steps must be called through this function, otherwise the returned tensor doesn't have: computation nodes, thread-datum which supports performance.</p><p>Building computation nodes is ignored when *no-grad* is t.</p><dl><dt>model</dt><dd>Your initialized model/node/optimizer objects</dd><dt>args</dt><dd>Arguments :forward needs</dd></dl><p>Example:
</p><pre><code class="lisp">(defnode Add nil
  :optimize t
  :parameters nil
  :forward  ((x y)
	     (sysconst (+ (data x)(data y))))
  :backward ((dy)(list dy dy)))

(call (Add)(const 1.0)(const 1.0))
;=&gt;Const(2.0)

</code></pre><p>Output: Waffetensor of list which comprised of waffetensor.</p></div></div>
<div class="codex-doc-node codex-operator codex-macro"><code class="codex-name">with-calling-layers</code><code class="codex-lambda-list">(input &amp;rest layers)</code><div class="codex-docstring"><p>This macro allows to sequentially call layers.</p><p>the argument <code class="codex-param">input</code> must be a tensor.</p><p>Refering each layers from (self) macro, destructively modifying x with the returned value.</p><p>Note: This macro supposes models to be returned a single tensor, not a list.</p><pre><code class="lisp">(defmodel MLP (activation)
   :parameters ((layer1   (denselayer (* 28 28) 512 T activation))
   	        (layer2   (denselayer 512 256 T activation))
	        (layer3   (linearlayer 256 10 T)))
   :forward ((x)
	     (with-calling-layers x
	       (layer1 x)
 	       (layer2 x)
               (layer3 x))))
</code></pre><p>For the different arguments.</p><pre><code class="lisp">(with-calling-layers x
     (layer1 x 1 1)
     (layer2 1 x 2)
     (layer3 x y))
</code></pre><p>Output: An last value of layers.</p></div></div>

<h1 id="displaying-tensors">Displaying Tensors</h1><p><p>
<div class="codex-doc-node codex-variable"><code class="codex-name">*default-backend*</code><div class="codex-docstring">Default backend cl-waffe uses. Default: :mgl</div></div></p><p>Configs when printing tensor.<div class="codex-doc-node codex-variable"><code class="codex-name">*print-char-max-len*</code><div class="codex-docstring">When printing tensor, the character displayed following this param.
(e.g. When 5, in your terminal, 1.12345d0 =&gt; 1.1234...)
Default: 5</div></div>
<div class="codex-doc-node codex-variable"><code class="codex-name">*print-arr-max-size*</code><div class="codex-docstring">When printing tensor, the tensor displayed following this param.
(e.g. When 5, in your terminal, (1 2 3 4 5 6 7 8 9 10) =&gt; (1 2 3 ... 4 5 6))
Default: 6</div></div>
<div class="codex-doc-node codex-variable"><code class="codex-name">*print-mat-max-size*</code><div class="codex-docstring">When printing tensor, the tensor displayed following this param.
(e.g. When 3, in your terminal, ((1)(2)(3)(4)) =&gt; ((1)(2) ... (4)))</div></div>
</p></p><h1 id="types">Types</h1><p>
<div class="codex-doc-node codex-type"><code class="codex-name">waffetensorcontenttype</code><code class="codex-type-def">nil</code><div class="codex-docstring"><p>An type of data that allowed to make tensors with (const ~) or (tensor ~).</p><p>cl-waffe automatically coerce them to arbitary types</p><p>`(or mgl-mat:mat
     simple-array
     waffesupporteddatatype)</p></div></div>
<div class="codex-doc-node codex-type"><code class="codex-name">waffesupporteddatatype</code><code class="codex-type-def">nil</code><div class="codex-docstring"><p>An type of waffe-tensor's content type,</p><p>`(or fixnum float null cons function ratio)</p></div></div>

</p><h1 id="lazy-evaluation">Lazy evaluation</h1><p>In default cl-waffe produces lazy-evaluated computation nodes.</p><p>A function (!transpose tensor) is a good example to demonstrate.</p><pre><code class="lisp">(setq a (!randn `(10 5)))
;#Const(((0.483... -0.52... -1.44... -0.06... 0.185...)        
;                 ...
;        (-0.85... 1.668... -0.27... 0.016... -0.45...)) :mgl t :shape (10 5))

(setq a (!transpose a))
;#Const(#&lt;FUNCTION (LABELS CL-WAFFE.BACKENDS.MGL::LAZYTRANSPOSE :IN CL-WAFFE.BACKENDS.MGL::LAZY-EVAL-TRANSPOSE) {100C25EBEB}&gt;)

(!shape a) ; Shapes can be accesed correctly (5 10)

; Transpose will be used with !matmul.

(!matmul a (!randn `(10 5)))
;#Const(((-5.39... 1.782... 2.277... -6.13... -6.14...)        
;                 ...
;        (-3.24... -1.60... 4.533... -2.23... 0.736...)) :mgl t :shape (5 5))

; After being called with (value tensor), lazy-evaluate is done and a is now:

;#Const(((0.483... -0.52... -1.44... -0.06... 0.185...)        
;                 ...
;        (-0.85... 1.668... -0.27... 0.016... -0.45...)) :mgl t :shape (10 5))

; Transpose won't destruct a.

; If you don't want to use lazy-evaluation, (!transpose1 tensor) is available. See Operators.
</code></pre><p>Lazy-Evaluation will be enabled when...</p><ol><li>a function (!transpose tensor)</li><li>JIT is enabled</li><li>Traicing is enabled</li></ol><h1 id="broadcasting">Broadcasting</h1><p>cl-waffe supports broadcasting tensors like Numpy.</p><p>Broadcasting do:
</p><ol><li>If the dimension of two tensors doesn't match in specified axis, repeats them if can (the number of axes on either axis is 1.). Otherwise errors.</li><li>If the two tensor's dims doesn't match, add one to the head of lesser Tensor's dim.</li></ol><p>Broadcasting is available to these operations.</p><ol><li>!add</li><li>!sub</li><li>!mul</li><li>!div</li><li>(setf !aref)</li></ol><p>
</p><pre><code class="lisp">;(!randn `(10))'s dim became: `(10) -&gt; `(1 10) -&gt; repeat it with (:axis = 1, :repeat-num = 10)
(!add (!randn `(10 10))(!randn `(10)))
;#Const(((-0.77... -0.32... ~ 1.563... -2.87...)        
;                 ...
;        (0.077... 3.698... ~ 1.669... -1.51...)) :mgl t :shape (10 10))

;The first argument of !add will be repeated with (:axis=1, :repeat-num=3)
(!add (!randn `(10 1 10))(!randn `(10 3 10)))
;#Const((((3.238... 0.185... ~ 2.035... -1.33...)         
;                   ...
;         (0.302... -0.20... ~ 1.731... -0.58...))        
;                 ...
;        ((-0.93... 0.992... ~ -1.50... -2.81...)         
;                   ...
;         (1.669... 0.659... ~ 1.218... -0.88...))) :mgl t :shape (10 3 10))
</code></pre><p>
</p><h1 id="jit">JIT</h1><p>Currently this feature is disabled.</p><p>cl-waffe dynamically defines kernel... (its performance problems remain to be solved.)</p><h1 id="tracing">Tracing</h1><p>Currently this feature is disabled. (cuz it's unstable)</p><p>cl-waffe can optimize define-by-run style codes by tracing their usage...
</p><h1 id="compute-tensors-in-a-destructive-way">Compute tensors in a destructive way</h1><p>In general, the cl-waffe APIs follow the following simple rules:</p><p>Side Effect Rules:
</p><ol><li>Operators whose names begin with ! will <b>copy</b> a base tensor and <b>produce a new matrix</b> every time they are called.</li><li>Operators whose names begin with !! will <b>destructively</b> assign a result to the <b>first argument.</b></li><li>When the destructive operator's first argument is not a mat, assign a result to the <b>second argument.</b> otherwise create a new mat.</li></ol><p>Note: Destructive Operation only supports when the tensor is a type of mgl-mat:mat.</p><p>As a numerical library, creating a new tensors each calculation step is only a waste of memory-space. In term of speed/memory, it is recommended to use destructive operations.</p><p>The code written in non-destructive APIs can be rewritten with destructive APIs in a simple way as all you have to do is follow the rules below:</p><p>First, prepare the fomula where all operations are non-destructive. In the case of (!exp (!exp x)), this operation creates a new tensor whose shape is the same as x for twice times. To rewrite it without making a new side effect, the deeper !exp should be rewritten to (!!exp ). That is, (!!exp (!exp x)).</p><p>Let's take a another example of making BatchNorm2D faster.</p><p>This is a slower ver of softmax.</p><pre><code class="lisp">(defun !average (x)
  (let ((z (!sum x 1))
	(batch-size (!shape x 0)))
    (!div z batch-size)))

(defun softmax (x)
  (let* ((x1 (!sub x (!average x)))
         (xe (!exp x1))
	 (z (!sum xe 1)))
     (!div xe z)))
</code></pre><p>Benchmarking it with time macro, it is:</p><pre><code class="lisp">(setq a (!randn `(1000 1000)))
;#Const(((0.129... -0.92... ~ -1.01... -0.86...)        
;                 ...
;        (-0.48... -0.04... ~ 0.375... 1.610...)) :mgl t :shape (1000 1000))

(time (softmax a))
;Evaluation took:
;  0.022 seconds of real time
;  0.021648 seconds of total run time (0.020327 user, 0.001321 system)
;  100.00% CPU
;  52,580,716 processor cycles
;  1 page fault
;  20,031,088 bytes consed
  
;#Const(((6.757... 2.345... ~ 2.141... 2.490...)        
;                 ...
;        (3.850... 5.976... ~ 9.139... 0.003...)) :mgl t :shape (1000 1000))

</code></pre><p>Rewriting it with a destructive API.</p><p>In !average function , z and x aren't combined because z is a new tensor produced by !sum which is a non-destructive API.</p><p>So, !div should be destructive.</p><p>!average become:</p><pre><code class="lisp">(defun !average (x)
  (let ((z (!sum x 1))
	(batch-size (!shape x 0)))
    (!!div z batch-size)))
</code></pre><p>Rewrite Softmax using similar steps.</p><pre><code class="lisp">(defun softmax (x)
  (let* ((x1 (!!mul -1.0 (!!sub (!average x) x))) ; Reversing x and (!average) in !sub, the operator returns -1.0x result.
         (xe (!!exp x1))
	 (z (!sum xe 1)))
     (!!div xe z)))
</code></pre><p>So, the whole code is:</p><pre><code class="lisp">(defun !average (x)
  (let ((z (!sum x 1))
	(batch-size (!shape x 0)))
    (!!div z batch-size)))

(defun softmax (x)
  (let* ((x1 (!!mul -1.0 (!!sub (!average x) x))) ; Reversing x and (!average) in !sub, the operator returns -1.0x result.
         (xe (!!exp x1))
	 (z  (!sum xe 1)))
     (!!div xe z)))
</code></pre><p>Benchmarking it, it is:</p><pre><code class="lisp">(time (softmax a))
;Evaluation took:
;  0.019 seconds of real time
;  0.019877 seconds of total run time (0.019687 user, 0.000190 system)
;  105.26% CPU
;  44,664,672 processor cycles
;  16,032,704 bytes consed
  
  
;#Const(((6.757... 2.345... ~ 2.141... 2.490...)        
;                 ...
;        (3.850... 5.976... ~ 9.139... 0.003...)) :mgl t :shape (1000 1000))

(print a) ; A is not destructed.
;#Const(((0.129... -0.92... ~ -1.01... -0.86...)        
;                 ...
;        (-0.48... -0.04... ~ 0.375... 1.610...)) :mgl t :shape (1000 1000))
</code></pre><p>Compared to pure mgl-mat's implementation.</p><pre><code class="lisp">(defun softmax! (x)
  (let ((result (make-mat (!shape x)))
        (tmp    (make-mat `(1 ,@(cdr (!shape x)))))
	(x      (copy-mat (data x))))
       (sum! x tmp :axis 1)
       (scal! (/ 1.0 (mat-dimension x 1)) tmp)
       (fill! 1.0 result)
       (scale-rows! tmp result)
       (axpy! -1.0 result x)
       (.exp! x)
       (sum! x tmp :axis 1)
       (fill! 1.0 result)
       (scale-rows! tmp result)
       (.inv! result)
       (const (.*! x result))))

(time (softmax! a))
;Evaluation took:
;  0.016 seconds of real time
;  0.017635 seconds of total run time (0.015160 user, 0.002475 system)
;  112.50% CPU
;  38,725,238 processor cycles
;  8,030,512 bytes consed
  
;#Const(((6.757... 2.345... ~ 2.141... 2.490...)        
;                 ...
;        (3.850... 5.976... ~ 9.139... 0.003...)) :mgl t :shape (1000 1000))
</code></pre><p>cl-waffe has a lot of challenges in terms of memory usage, but in terms of speed it comes close to writing with mgl-mat alone.</p><p>Currently(2023/2/26), the benchmark is (added type declations):</p><pre><code class="lisp">(defun !average (x)
  (declare (optimize (speed 3))
           (type waffetensor x))
  (let ((z (!sum x 1))
	(batch-size (!shape x 0)))
    (!div z batch-size)))

(defun softmax (x)
  (declare (optimize (speed 3))
           (type waffetensor x))
  (let* ((x1 (!sub x (!average x)))
         (xe (!exp x1))
	 (z (!sum xe 1)))
     (!div xe z)))

; destructive ver.
(defun !average1 (x)
  (declare (optimize (speed 3))
           (type waffetensor x))
  (let ((z (!sum x 1))
	(batch-size (!shape x 0)))
    (!!div z batch-size)))

(defun softmax1 (x)
  (declare (optimize (speed 3))
           (type waffetensor x))
  (let* ((x1 (!!mul -1.0 (!!sub (!average1 x) x)))
         (xe (!!exp x1))
	 (z  (!sum xe 1)))
     (!!div xe z)))

; mgl-mat

(defun softmax2 (x)
  (declare (optimize (speed 3))
           (type waffetensor x))
  (let ((result (make-mat (!shape x)))
        (tmp    (make-mat `(1 ,@(cdr (!shape x)))))
	(x      (copy-mat (data x))))
       (sum! x tmp :axis 1)
       (scal! (/ 1.0 (mat-dimension x 1)) tmp)
       (fill! 1.0 result)
       (scale-rows! tmp result)
       (axpy! -1.0 result x)
       (.exp! x)
       (sum! x tmp :axis 1)
       (fill! 1.0 result)
       (scale-rows! tmp result)
       (.inv! result)
       (const (.*! x result))))

(defparameter n 1000)

(time (loop for i fixnum upfrom 0 below n
            do (softmax a)))
;Evaluation took:
;  0.340 seconds of real time
;  0.326843 seconds of total run time (0.322840 user, 0.004003 system)
;  [ Run times consist of 0.003 seconds GC time, and 0.324 seconds non-GC time. ]
;  96.18% CPU
;  784,081,358 processor cycles
;  233,002,704 bytes consed

(time (loop for i fixnum upfrom 0 below n
            do (softmax1 a)))
;Evaluation took:
;  0.347 seconds of real time
;  0.335853 seconds of total run time (0.332290 user, 0.003563 system)
;  [ Run times consist of 0.003 seconds GC time, and 0.333 seconds non-GC time. ]
;  96.83% CPU
;  801,195,214 processor cycles
;  187,704,864 bytes consed

(time (loop for i fixnum upfrom 0 below n
            do (softmax2 a)))
;Evaluation took:
;  0.232 seconds of real time
;  0.219684 seconds of total run time (0.216419 user, 0.003265 system)
;  [ Run times consist of 0.003 seconds GC time, and 0.217 seconds non-GC time. ]
;  94.83% CPU
;  535,165,520 processor cycles
;  92,326,496 bytes consed
</code></pre><h2 id="creating-destructive-operations">Creating Destructive Operations</h2><p>Using these macros below, you can inform cl-waffe's kernel of which tensors should be destructed.
  <div class="codex-doc-node codex-operator codex-macro"><code class="codex-name">!allow-destruct</code><code class="codex-lambda-list">(tensor)</code><div class="codex-docstring"><p>Tensors which path through this macro are allowed to be destructed by cl-waffe's kernel.</p><p>
In default, cl-waffe's operators won't make side effects.
</p><pre><code class="lisp">(setq a (!randn `(3 3)))

;#Const(((0.811... -0.43... -0.91...)        
;                 ...
;        (0.959... -0.62... 1.150...)) :mgl t :shape (3 3))

(!exp a)
;#Const(((2.252... 0.645... 0.400...)        
;                 ...
;        (2.610... 0.534... 3.159...)) :mgl t :shape (3 3))

(print a)
;#Const(((0.811... -0.43... -0.91...)        
;                 ...
;        (0.959... -0.62... 1.150...)) :mgl t :shape (3 3))
</code></pre><p>However, This macro let kernel know that the given tensor is allowed to destruct(i.e.: the result is overwritten)</p><pre><code class="lisp">(setq a (!randn `(3 3)))

;#Const(((0.811... -0.43... -0.91...)        
;                 ...
;        (0.959... -0.62... 1.150...)) :mgl t :shape (3 3))

(!allow-destruct a)
; T

(!exp a)
;#Const(((2.252... 0.645... 0.400...)        
;                 ...
;        (2.610... 0.534... 3.159...)) :mgl t :shape (3 3))

(print a) ; You can see the result is overwritten.
;#Const(((2.252... 0.645... 0.400...)        
;                 ...
;        (2.610... 0.534... 3.159...)) :mgl t :shape (3 3))
</code></pre><p>Avoiding copy, destructive operations are superior in terms of memory usage.</p><pre><code class="lisp">(setq a (!randn `(100 100)))

(time (!exp a))
;Evaluation took:
;  0.000 seconds of real time
;  0.000275 seconds of total run time (0.000219 user, 0.000056 system)
;  100.00% CPU
;  498,150 processor cycles
;  31,264 bytes consed

(!allow-destruct a)

(time (!exp a))
; Evaluation took:
;  0.000 seconds of real time
;  0.000178 seconds of total run time (0.000160 user, 0.000018 system)
;  100.00% CPU
;  273,646 processor cycles
;  0 bytes consed 
</code></pre><p>See also: !disallow-destruct which does the opposite.
</p></div></div>
  <div class="codex-doc-node codex-operator codex-macro"><code class="codex-name">!disallow-destruct</code><code class="codex-lambda-list">(tensor)</code><div class="codex-docstring">Tensors that path through this macro are not destructed.<pre><code class="lisp">(setq a (!randn `(3 3)))
;#Const(((1.084... -1.10... 1.406...)        
;                 ...
;        (1.044... 0.059... -0.53...)) :mgl t :shape (3 3))

(!allow-destruct a)
; T
(!disallow-destruct a)
; NIL

(!exp a)
;#Const(((2.957... 0.329... 4.080...)        
;                 ...
;        (2.840... 1.060... 0.584...)) :mgl t :shape (3 3))

(print a) ; a is kept remained.
;#Const(((1.084... -1.10... 1.406...)        
;                 ...
;        (1.044... 0.059... -0.53...)) :mgl t :shape (3 3))
</code></pre></div></div>

</p><p>
</p><h1 id="logging">Logging</h1><p>
  <div class="codex-doc-node codex-operator codex-macro"><code class="codex-name">with-verbose</code><code class="codex-lambda-list">(&amp;body body)</code><div class="codex-docstring">In the codes below, the computation nodes will be displayed when (backward out)</div></div>

</p><h1 id="backends">Backends</h1><p>
  <div class="codex-doc-node codex-operator codex-macro"><code class="codex-name">define-node-extension</code><code class="codex-lambda-list">(name &amp;key optimize backend forward backward)</code><div class="codex-docstring"><p>Adds a new backend to the defined node.</p><p>The type of backend is managed by keywords. The backend defined in defnode is always :mgl.</p><p>Defined backends can be switched by the macro <code>(with-backend backend)</code>.</p><p>As long as *restart-non-exist-backend* is t, when a computation node reaches a backend that is not defined, :mgl is called, otherwise the condition backend-doesnt-exists will occurs.</p><p>Example:</p><pre><code class="lisp">(define-node-extension cl-waffe::AddTensor
  :backend :test-backend
  :forward ((x y)
        (const (+ 1 1)))
  :backward ((dy)
         (list dy dy)))

(with-backend :mgl
   (print (!add 10 10))) ;=&gt; Const(20)

(with-backend :test-backend
   (print (!add 10 10))) ;=&gt; Const(2)

(with-backend :hogehoge
   (print (!add 10 10))) ; =&gt; Const(20)

(let ((*restart-non-exist-backend* nil))
    (with-backend :hogehoge
        (print (!add 10 10)))) ;=&gt; Evaluation aborted on #&lt;CL-WAFFE::BACKEND-DOESNT-EXISTS {100FA18C43}&gt;.
</code></pre><p>
</p></div></div>
  <div class="codex-doc-node codex-operator codex-macro"><code class="codex-name">with-backend</code><code class="codex-lambda-list">(backend &amp;body body)</code><div class="codex-docstring"><p>Switches a backend.</p><p>See also: define-node-extension</p></div></div>
  <div class="codex-doc-node codex-variable"><code class="codex-name">*restart-non-exist-backend*</code><div class="codex-docstring">When t, in the case when the specified backend doesn't exist, cl-waffe calls a standard implementation backend</div></div>

</p>
      </div>
    </main>
  </article>
  <footer>
    <div class="info">
      Created with <a href="https://github.com/CommonDoc/codex">Codex</a>.
    </div>
  </footer>
  <script>
   HighlightLisp.highlight_auto();
  </script>

  </body>
</html>
