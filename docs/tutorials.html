<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <title>
  Tutorials &ndash; cl-waffe
</title>
    <link rel="stylesheet" href="static/style.css"/>
    
  <link rel="stylesheet" href="static/highlight.css"/>
  <script src="static/highlight.js"></script>
  <style>
   /* Highlight the current top-level TOC item, and hide the TOC of all other items */

   .toc a[data-node="tutorials"] {
       /*color: #AD3108;*/
   }

   .toc ol {
       display: none;
   }

   .toc li a[data-node="tutorials"] {
       font-weight: bold;
   }

   .toc li a[data-node="tutorials"] + ol {
       display: block;
   }

   .toc li a[data-node="tutorials"] + ol li {
       margin-left: 10px;
   }
  </style>

  </head>
  <body>
    
  <h1 class="doc-title">cl-waffe</h1>
  <article id="article" data-section="tutorials">
    <aside>
      <ol class="toc"><li><a href="overview.html" data-node="overview">Overview</a><ol><li><a href="overview.html#about-this-project" data-node="about-this-project">About This Project</a></li><li><a href="overview.html#links" data-node="links">Links</a></li><li><a href="overview.html#workloads" data-node="workloads">Workloads</a></li><li><a href="overview.html#lla-backend" data-node="lla-backend">LLA Backend</a></li><li><a href="overview.html#when-memory-heap-is-exhasted?" data-node="when-memory-heap-is-exhasted?">When Memory Heap Is Exhasted?</a></li></ol></li><li><a href="tutorials.html" data-node="tutorials">Tutorials</a><ol><li><a href="tutorials.html#introducing-waffetensor" data-node="introducing-waffetensor">Introducing WaffeTensor</a><ol><li><a href="tutorials.html#what-can-waffetensor-do?" data-node="what-can-waffetensor-do?">What can WaffeTensor do?</a><ol><li><a href="tutorials.html#to-restore-computation-nodes" data-node="to-restore-computation-nodes">To Restore Computation Nodes</a></li><li><a href="tutorials.html#to-restore-gradients" data-node="to-restore-gradients">To Restore Gradients</a></li><li><a href="tutorials.html#to-distinguish-what-tensor-requires-gradients" data-node="to-distinguish-what-tensor-requires-gradients">To distinguish What Tensor Requires Gradients</a></li><li><a href="tutorials.html#to-store-lazy-evaluated-object" data-node="to-store-lazy-evaluated-object">To Store Lazy-Evaluated Object</a></li></ol></li><li><a href="tutorials.html#parameter-and-const" data-node="parameter-and-const">Parameter and Const</a><ol><li><a href="tutorials.html#initialize-constants" data-node="initialize-constants">Initialize Constants</a></li><li><a href="tutorials.html#initialize-parameter" data-node="initialize-parameter">Initialize Parameter</a></li><li><a href="tutorials.html#parameter-vs-constant" data-node="parameter-vs-constant">Parameter vs Constant</a></li></ol></li></ol></li><li><a href="tutorials.html#defnode-and-call" data-node="defnode-and-call">defnode and call</a></li><li><a href="tutorials.html#writing-node-extensions" data-node="writing-node-extensions">Writing Node Extensions</a></li><li><a href="tutorials.html#mnist-example" data-node="mnist-example">MNIST Example</a><ol><li><a href="tutorials.html#defines-your-model" data-node="defines-your-model">Defines your model</a></li><li><a href="tutorials.html#define-your-trainer" data-node="define-your-trainer">define your trainer</a></li></ol></li></ol></li><li><a href="tips.html" data-node="tips">Tips</a><ol><li><a href="destructive-operations.html" data-node="destructive-operations">Destructive Operations</a></li><li><a href="using-other-libraries-with-facet-apis.html" data-node="using-other-libraries-with-facet-apis">Using other libraries with Facet APIs</a></li><li><a href="zero-cost-transpose.html" data-node="zero-cost-transpose">Zero-cost Transpose</a></li><li><a href="logging.html" data-node="logging">Logging</a></li></ol></li><li><a href="features.html" data-node="features">Features</a><ol><li><a href="defmodel.html" data-node="defmodel">defmodel</a></li><li><a href="defnode.html" data-node="defnode">defnode</a></li><li><a href="defoptimizer.html" data-node="defoptimizer">defoptimizer</a></li><li><a href="deftrainer.html" data-node="deftrainer">deftrainer</a></li><li><a href="defdataset.html" data-node="defdataset">defdataset</a></li><li><a href="environment-variables.html" data-node="environment-variables">Environment Variables</a></li></ol></li><li><a href="package--cl-waffe.html" data-node="package--cl-waffe">Package :cl-waffe</a><ol><li><a href="tensors.html" data-node="tensors">Tensors</a></li><li><a href="gradients.html" data-node="gradients">Gradients</a></li><li><a href="four-arithmetic-operations.html" data-node="four-arithmetic-operations">Four Arithmetic Operations</a></li><li><a href="summarize.html" data-node="summarize">Summarize</a></li><li><a href="multiplying-matrices.html" data-node="multiplying-matrices">Multiplying matrices</a></li><li><a href="trigonometric-functions.html" data-node="trigonometric-functions">Trigonometric Functions</a></li><li><a href="mathematical-functions.html" data-node="mathematical-functions">Mathematical Functions</a></li><li><a href="reshaping.html" data-node="reshaping">Reshaping</a></li><li><a href="shaping.html" data-node="shaping">Shaping</a></li><li><a href="concatenate-and-split.html" data-node="concatenate-and-split">Concatenate and Split</a></li><li><a href="iterations-and-making-copy.html" data-node="iterations-and-making-copy">Iterations and Making Copy</a></li><li><a href="sampling-distributions.html" data-node="sampling-distributions">Sampling Distributions</a></li><li><a href="initializes-the-tensor.html" data-node="initializes-the-tensor">Initializes the tensor</a></li><li><a href="activations.html" data-node="activations">Activations</a></li><li><a href="0-logging.html" data-node="0-logging">Logging</a></li><li><a href="dtype.html" data-node="dtype">Dtype</a></li><li><a href="extensions.html" data-node="extensions">Extensions</a></li><li><a href="1-destructive-operations.html" data-node="1-destructive-operations">Destructive Operations</a></li><li><a href="objects.html" data-node="objects">Objects</a></li><li><a href="trainer.html" data-node="trainer">Trainer</a></li><li><a href="dataset.html" data-node="dataset">Dataset</a></li><li><a href="model-list.html" data-node="model-list">Model List</a></li><li><a href="printing.html" data-node="printing">Printing</a></li></ol></li><li><a href="package--cl-waffe.nn.html" data-node="package--cl-waffe.nn">Package :cl-waffe.nn</a></li><li><a href="package--cl-waffe.optimizers.html" data-node="package--cl-waffe.optimizers">Package :cl-waffe.optimizers</a></li><li><a href="conditions.html" data-node="conditions">Conditions</a></li><li><a href="<apis--cl-waffe>.html" data-node="<apis--cl-waffe>">&lt;APIs: cl-waffe&gt;</a><ol><li><a href="!normal.html" data-node="!normal">!normal</a></li><li><a href="!randn.html" data-node="!randn">!randn</a></li><li><a href="!uniform-random.html" data-node="!uniform-random">!uniform-random</a></li><li><a href="!beta.html" data-node="!beta">!beta</a></li><li><a href="!gamma.html" data-node="!gamma">!gamma</a></li><li><a href="!chisquare.html" data-node="!chisquare">!chisquare</a></li><li><a href="!bernoulli.html" data-node="!bernoulli">!bernoulli</a></li><li><a href="!binomial.html" data-node="!binomial">!binomial</a></li><li><a href="!random-with.html" data-node="!random-with">!random-with</a></li><li><a href="!random.html" data-node="!random">!random</a></li><li><a href="!zeros-like.html" data-node="!zeros-like">!zeros-like</a></li><li><a href="!ones-like.html" data-node="!ones-like">!ones-like</a></li><li><a href="!full-like.html" data-node="!full-like">!full-like</a></li><li><a href="!zeros.html" data-node="!zeros">!zeros</a></li><li><a href="!ones.html" data-node="!ones">!ones</a></li><li><a href="!fill.html" data-node="!fill">!fill</a></li><li><a href="!shape.html" data-node="!shape">!shape</a></li><li><a href="!dims.html" data-node="!dims">!dims</a></li><li><a href="!size.html" data-node="!size">!size</a></li><li><a href="waffetensor.html" data-node="waffetensor">WaffeTensor</a></li><li><a href="parameter.html" data-node="parameter">parameter</a></li><li><a href="data.html" data-node="data">data</a></li><li><a href="value.html" data-node="value">value</a></li><li><a href="backward.html" data-node="backward">backward</a></li><li><a href="with-no-grad.html" data-node="with-no-grad">with-no-grad</a></li><li><a href="*no-grad*.html" data-node="*no-grad*">*no-grad*</a></li><li><a href="!add.html" data-node="!add">!add</a><ol><li><a href="examples.html" data-node="examples">Examples</a></li></ol></li><li><a href="!!add.html" data-node="!!add">!!add</a></li><li><a href="!sub.html" data-node="!sub">!sub</a><ol><li><a href="2-examples.html" data-node="2-examples">Examples</a></li></ol></li><li><a href="!!sub.html" data-node="!!sub">!!sub</a></li><li><a href="!mul.html" data-node="!mul">!mul</a><ol><li><a href="3-examples.html" data-node="3-examples">Examples</a></li></ol></li><li><a href="!!mul.html" data-node="!!mul">!!mul</a></li><li><a href="!div.html" data-node="!div">!div</a><ol><li><a href="4-examples.html" data-node="4-examples">Examples</a></li></ol></li><li><a href="!sum.html" data-node="!sum">!sum</a><ol><li><a href="arguments.html" data-node="arguments">arguments</a></li><li><a href="example.html" data-node="example">Example</a></li></ol></li><li><a href="!mean.html" data-node="!mean">!mean</a><ol><li><a href="5-example.html" data-node="5-example">Example</a></li></ol></li><li><a href="!dot.html" data-node="!dot">!dot</a><ol><li><a href="6-example.html" data-node="6-example">Example</a></li></ol></li><li><a href="!matmul.html" data-node="!matmul">!matmul</a></li><li><a href="!sin.html" data-node="!sin">!sin</a><ol><li><a href="7-example.html" data-node="7-example">Example</a></li></ol></li><li><a href="!cos.html" data-node="!cos">!cos</a><ol><li><a href="8-example.html" data-node="8-example">Example</a></li></ol></li><li><a href="!tan.html" data-node="!tan">!tan</a><ol><li><a href="9-example.html" data-node="9-example">Example</a></li></ol></li><li><a href="!asin.html" data-node="!asin">!asin</a></li><li><a href="!acos.html" data-node="!acos">!acos</a></li><li><a href="!atan.html" data-node="!atan">!atan</a></li><li><a href="!sinh.html" data-node="!sinh">!sinh</a><ol><li><a href="10-example.html" data-node="10-example">Example</a></li></ol></li><li><a href="!cosh.html" data-node="!cosh">!cosh</a><ol><li><a href="11-example.html" data-node="11-example">Example</a></li></ol></li><li><a href="!tanh.html" data-node="!tanh">!tanh</a></li><li><a href="!asinh.html" data-node="!asinh">!asinh</a></li><li><a href="!acosh.html" data-node="!acosh">!acosh</a></li><li><a href="!atanh.html" data-node="!atanh">!atanh</a></li><li><a href="!abs.html" data-node="!abs">!abs</a></li><li><a href="!log.html" data-node="!log">!log</a><ol><li><a href="12-example.html" data-node="12-example">Example</a></li></ol></li><li><a href="!exp.html" data-node="!exp">!exp</a><ol><li><a href="13-example.html" data-node="13-example">Example</a></li></ol></li><li><a href="!pow.html" data-node="!pow">!pow</a><ol><li><a href="14-example.html" data-node="14-example">Example</a></li></ol></li><li><a href="!sqrt.html" data-node="!sqrt">!sqrt</a><ol><li><a href="15-example.html" data-node="15-example">Example</a></li></ol></li><li><a href="!argmax.html" data-node="!argmax">!argmax</a><ol><li><a href="16-example.html" data-node="16-example">Example</a></li></ol></li><li><a href="!argmin.html" data-node="!argmin">!argmin</a><ol><li><a href="17-example.html" data-node="17-example">Example</a></li></ol></li><li><a href="!squeeze.html" data-node="!squeeze">!squeeze</a><ol><li><a href="18-example.html" data-node="18-example">Example</a></li></ol></li><li><a href="!unsqueeze.html" data-node="!unsqueeze">!unsqueeze</a><ol><li><a href="19-example.html" data-node="19-example">Example</a></li></ol></li><li><a href="!reshape.html" data-node="!reshape">!reshape</a><ol><li><a href="20-example.html" data-node="20-example">Example</a></li></ol></li><li><a href="!repeats.html" data-node="!repeats">!repeats</a><ol><li><a href="21-example.html" data-node="21-example">Example</a></li></ol></li><li><a href="!flatten.html" data-node="!flatten">!flatten</a></li><li><a href="!transpose.html" data-node="!transpose">!transpose</a><ol><li><a href="22-example.html" data-node="22-example">Example</a></li></ol></li><li><a href="!transpose1.html" data-node="!transpose1">!transpose1</a><ol><li><a href="23-example.html" data-node="23-example">Example</a></li></ol></li><li><a href="!concatenate.html" data-node="!concatenate">!concatenate</a><ol><li><a href="24-example.html" data-node="24-example">Example</a></li></ol></li><li><a href="!stack.html" data-node="!stack">!stack</a><ol><li><a href="25-example.html" data-node="25-example">Example</a></li></ol></li><li><a href="!split.html" data-node="!split">!split</a><ol><li><a href="26-example.html" data-node="26-example">Example</a></li></ol></li><li><a href="!hstack.html" data-node="!hstack">!hstack</a></li><li><a href="!vstack.html" data-node="!vstack">!vstack</a></li><li><a href="!aref.html" data-node="!aref">!aref</a></li><li><a href="!where.html" data-node="!where">!where</a><ol><li><a href="27-example.html" data-node="27-example">Example</a></li></ol></li><li><a href="!index.html" data-node="!index">!index</a></li><li><a href="!filter.html" data-node="!filter">!filter</a></li><li><a href="!arange.html" data-node="!arange">!arange</a><ol><li><a href="(-!arange-stop-).html" data-node="(-!arange-stop-)">(!arange stop)</a></li><li><a href="(-!arange-start-stop-).html" data-node="(-!arange-start-stop-)">(!arange start stop)</a></li><li><a href="(-!arange-start-stop-step-).html" data-node="(-!arange-start-stop-step-)">(!arange start stop step)</a></li></ol></li><li><a href="!relu.html" data-node="!relu">!relu</a></li><li><a href="!sigmoid.html" data-node="!sigmoid">!sigmoid</a></li><li><a href="!gelu.html" data-node="!gelu">!gelu</a></li><li><a href="!leakey-relu.html" data-node="!leakey-relu">!leakey-relu</a></li><li><a href="!swish.html" data-node="!swish">!swish</a></li><li><a href="!softmax.html" data-node="!softmax">!softmax</a></li><li><a href="with-verbose.html" data-node="with-verbose">with-verbose</a></li><li><a href="with-dtype.html" data-node="with-dtype">with-dtype</a></li><li><a href="dtypecase.html" data-node="dtypecase">dtypecase</a></li><li><a href="define-with-typevar.html" data-node="define-with-typevar">define-with-typevar</a></li><li><a href="with-backend.html" data-node="with-backend">with-backend</a></li><li><a href="define-node-extension.html" data-node="define-node-extension">define-node-extension</a></li><li><a href="*restart-non-exist-backend*.html" data-node="*restart-non-exist-backend*">*restart-non-exist-backend*</a></li><li><a href="!allow-destruct.html" data-node="!allow-destruct">!allow-destruct</a></li><li><a href="!disallow-destruct.html" data-node="!disallow-destruct">!disallow-destruct</a></li><li><a href="28-defnode.html" data-node="28-defnode">defnode</a></li><li><a href="29-defmodel.html" data-node="29-defmodel">defmodel</a></li><li><a href="30-defoptimizer.html" data-node="30-defoptimizer">defoptimizer</a></li><li><a href="call.html" data-node="call">call</a></li><li><a href="call-backward.html" data-node="call-backward">call-backward</a></li><li><a href="self.html" data-node="self">self</a></li><li><a href="save-for-backward.html" data-node="save-for-backward">save-for-backward</a></li><li><a href="get-forward-caller.html" data-node="get-forward-caller">get-forward-caller</a></li><li><a href="get-backward-caller.html" data-node="get-backward-caller">get-backward-caller</a></li><li><a href="with-calling-layers.html" data-node="with-calling-layers">with-calling-layers</a></li><li><a href="31-deftrainer.html" data-node="31-deftrainer">deftrainer</a></li><li><a href="step-model.html" data-node="step-model">step-model</a></li><li><a href="predict.html" data-node="predict">predict</a></li><li><a href="model.html" data-node="model">model</a></li><li><a href="update.html" data-node="update">update</a></li><li><a href="zero-grad.html" data-node="zero-grad">zero-grad</a></li><li><a href="32-defdataset.html" data-node="32-defdataset">defdataset</a></li><li><a href="get-dataset.html" data-node="get-dataset">get-dataset</a></li><li><a href="get-dataset-length.html" data-node="get-dataset-length">get-dataset-length</a></li><li><a href="33-model-list.html" data-node="33-model-list">model-list</a></li><li><a href="mlist.html" data-node="mlist">mlist</a></li><li><a href="mth.html" data-node="mth">mth</a></li><li><a href="grad.html" data-node="grad">grad</a></li></ol></li><li><a href="<apis--cl-waffe.nn>.html" data-node="<apis--cl-waffe.nn>">&lt;APIs: cl-waffe.nn&gt;</a></li><li><a href="<apis--cl-waffe.optimizers>.html" data-node="<apis--cl-waffe.optimizers>">&lt;APIs: cl-waffe.optimizers&gt;</a></li></ol>
    </aside>
    <main class="codex-section">
      <header>
        <h2 class="section-title">Tutorials</h2>
      </header>
      <div class="content">
        
<h1 id="introducing-waffetensor">Introducing WaffeTensor</h1><p>Most deep learning frameworks, represented by PyTorch's Tensor and Chainer's Variables, has their own data structures to store matrices. In cl-waffe, <b>WaffeTensor</b> is available and defined by Common Lisp's <b>defstruct</b>.</p><p>
⚠️ There is no guarantee that this design is technically mature.
</p><h2 id="what-can-waffetensor-do?">What can WaffeTensor do?</h2><p>Internally, All matrices created by cl-waffe is a type of mgl-mat, being accessed by the accessor (data tensor).</p><p>
<b>REPL:</b>
</p><pre><code class="lisp">CL-WAFFE&gt; (setq x (!randn `(3 3))) ; WaffeTensor
</code></pre><pre><code class="lisp">#Const(((0.050... 1.007... 0.258...)        
                 ...
        (-0.39... 0.869... -0.55...)) :dtype :float :shape (3 3) :backward NIL)
</code></pre><pre><code class="lisp">CL-WAFFE&gt; (data x) ;mgl-mat:mat
</code></pre><pre><code class="lisp">#&lt;MAT 3x3 AB #2A((0.050437 1.0072675 0.25835297)
                 (1.703179 -0.53816134 0.09240111)
                 (-0.39267328 0.8698013 -0.55995613))&gt;
</code></pre><p>In the same way, WaffeTensor can restore scalar object.</p><p>
<b>REPL:</b>
</p><pre><code class="lisp">CL-WAFFE&gt; (setq x (const 1.0)) : WaffeTensor
</code></pre><pre><code class="lisp">#Const(1.0 :dtype SINGLE-FLOAT :backward NIL)
</code></pre><pre><code class="lisp">CL-WAFFE&gt; (data x) ; single-float
</code></pre><pre><code class="lisp">1.0
</code></pre><p>That is, one of the main roles of WaffeTensor is to be <b>a wrapper for multiple data structures.</b></p><p>
You may well feel it is just rebundant for waffetensor to be only a wrapper. Of course, WaffeTensor has also these roles:
</p><h3 id="to-restore-computation-nodes">To Restore Computation Nodes</h3><p>Operations performed via cl-waffe, creates a <b>comutation nodes</b>. This can all be extended by the defnode and call macros described the defnode and call section.</p><p>
<b>Input</b>
</p><pre><code class="lisp">CL-WAFFE&gt;
(let ((a (const 1.0))
      (b (const 1.0)))
  (!add a b))
</code></pre><b>Output</b><pre><code class="lisp">#Const(2.0 :dtype SINGLE-FLOAT :backward &lt;Node: ADDTENSOR{W893}&gt;)
</code></pre><p>When gradient is not required (e.g.: predict), the macro <code>(with-no-grad)</code> would be useful.

<div class="codex-doc-node codex-operator codex-macro"><code class="codex-name">with-no-grad</code><code class="codex-lambda-list">(&amp;body body)</code><div class="codex-docstring">Below this macro, the parameter *no-grad* become t, which means: some operations are forcibly ignored. (e.g.: save-for-backward, building computation nodes)
<pre><code class="lisp">(with-no-grad
  (call (model) x))
</code></pre></div></div>
</p><p><b>Input</b>
</p><pre><code class="lisp">CL-WAFFE&gt;
(with-no-grad
    (let ((a (const 1.0))
	  (b (const 1.0)))
      (!add a b)))
</code></pre><b>Output</b><pre><code class="lisp">#Const(2.0 :dtype SINGLE-FLOAT :backward NIL)
</code></pre><p>
</p><h3 id="to-restore-gradients">To Restore Gradients</h3><p>WaffeTensors which created by <code>(parameter tensor)</code> macro, posses the gradients, where you can get via `(backward out)`

<div class="codex-doc-node codex-operator codex-macro"><code class="codex-name">parameter</code><code class="codex-lambda-list">(tensor)</code><div class="codex-docstring"><p>Redefining new-tensor where old-tensor is const or tensor.</p><p>The new-tensor can made grads.</p><p>Excepted usage is like:
</p><pre><code class="lisp">(setq my-param (parameter (!mul 0.01 (!randn `(10 10)))))
</code></pre><p>Note that: tensor's computation node that old-tensor has, will be lost. Only tensor's data and backend will be extended.</p><dl><dt>Input</dt><dd>Tensor (as usual, defined by (const)(sysconst)(tensor))
</dd><dt>Output</dt><dd>Tensor (as usual, defined by (tensor))
</dd></dl></div></div>
</p><p>
<div class="codex-doc-node codex-operator codex-function"><code class="codex-name">backward</code><code class="codex-lambda-list">(tensor)</code><div class="codex-docstring"><p>Compute back propagation by traversing the Tensor's computation node.</p><p>The parameters of the model defined by (tensor) or to which (Parameter tensor) is applied, store the gradient in grad slot.</p><p>Note that: tensor must be the shape of `(1) or single value. Otherwise an error occurs.</p><p>In the process calculating backward, new backwards won't be created. (*no-grad* automatically becomes t)</p><dl><dt>Input</dt><dd>WaffeTensor</dd><dt>Output</dt><dd>NIL</dd></dl></div></div>
</p><p><b>REPL:</b>
</p><pre><code class="lisp">CL-WAFFE&gt; (setq a (parameter (!randn `(3 3))))
</code></pre><pre><code class="lisp">#Parameter{((-1.07... -1.93... -0.07...)            
                         ...
            (1.353... 0.451... 2.473...)) :dtype :float :shape (3 3) :backward NIL}
</code></pre><pre><code class="lisp">CL-WAFFE&gt; (setq b (parameter (!randn `(3 3))))
</code></pre><pre><code class="lisp">#Parameter{((0.234... 0.449... -1.02...)            
                         ...
            (-0.42... -1.63... -0.34...)) :dtype :float :shape (3 3) :backward NIL}
</code></pre><pre><code class="lisp">CL-WAFFE&gt; (setq c (parameter (!randn `(3 3))))
</code></pre><pre><code class="lisp">#Parameter{((0.157... 1.040... -0.84...)            
                         ...
            (1.850... -0.26... -0.24...)) :dtype :float :shape (3 3) :backward NIL}
</code></pre><pre><code class="lisp">CL-WAFFE&gt; (setq z (!sum (!add (!mul a b) c))) ; computes z=a*b + c, and summarize it.
</code></pre><pre><code class="lisp">#Const(-0.5249139 :dtype SINGLE-FLOAT :backward &lt;Node: SUMUPTENSOR{W903}&gt;)
</code></pre><pre><code class="lisp">CL-WAFFE&gt; (backward z)
</code></pre><pre><code class="lisp">NIL
</code></pre><pre><code class="lisp">CL-WAFFE&gt; (grad a)
</code></pre><pre><code class="lisp">#&lt;MAT 3x3 B #2A((0.026024515 0.04989684 -0.11357514)
                (-0.07813747 -0.032786068 -0.11216043)
                (-0.047159225 -0.18221794 -0.038357873))&gt;
</code></pre><pre><code class="lisp">CL-WAFFE&gt; (grad b)
</code></pre><pre><code class="lisp">#&lt;MAT 3x3 B #2A((-0.11956648 -0.21451499 -0.008029957)
                (0.14240001 0.11439725 0.002615907)
                (0.15042241 0.050139852 0.27483448))&gt;
</code></pre><pre><code class="lisp">CL-WAFFE&gt; (grad c)
</code></pre><pre><code class="lisp">#&lt;MAT 3x3 BF #2A((0.11111111 0.11111111 0.11111111)
                 (0.11111111 0.11111111 0.11111111)
                 (0.11111111 0.11111111 0.11111111))&gt;
</code></pre><p>
<div class="codex-doc-node codex-operator codex-macro"><code class="codex-name">with-verbose</code><code class="codex-lambda-list">(&amp;body body)</code><div class="codex-docstring">In the codes below, the computation nodes will be displayed when (backward out)</div></div>
</p><p>(backward out) called inside of (with-verbose &amp;body body) macro, will display how the computation nodes are traced. It would be helpful for debugging.
</p><p>
</p><h3 id="to-distinguish-what-tensor-requires-gradients">To distinguish What Tensor Requires Gradients</h3><p>WaffeTensor that requires gradients, are represented by <code>(parameter tensor)</code>, on the other hand, don't requires one are <code>(const)</code>. Then, Computational nodes that have no parameters at the destination of back propagation do not need to keep a copy for gradient creation during forward propagation or to perform back propagation in the first place. WaffeTensor determines this dynamically during forward propagation.
</p><p>
</p><h3 id="to-store-lazy-evaluated-object">To Store Lazy-Evaluated Object</h3><p>You may notice that: some operators, like !transpose, creates lazy-evaluated tensor when get started with cl-waffe.</p><p>
<b>REPL:</b>
</p><pre><code class="lisp">CL-WAFFE&gt; (!transpose (!randn `(3 1)))
</code></pre><pre><code class="lisp">#Const(&lt;Transposed Tensor&gt; :shape (1 3) :backward &lt;Node: TRANSPOSETENSOR{W906}&gt;)
</code></pre><p>They behaves as if they're normal tensor (In fact, !shape !dims etc... works as usual), but aren't evaluated until (value tensor) is called.</p><p>
<b>REPL:</b>
</p><pre><code class="lisp">CL-WAFFE&gt; (setq transpose (!transpose (!randn `(3 1))))
</code></pre><pre><code class="lisp">#Const(&lt;Transposed Tensor&gt; :shape (1 3) :backward &lt;Node: TRANSPOSETENSOR{W907}&gt;)
</code></pre><pre><code class="lisp">CL-WAFFE&gt; (value transpose)
</code></pre><pre><code class="lisp">#&lt;MAT 1x3 B #2A((-2.362661 -1.4510747 -0.88706297))&gt;
</code></pre><pre><code class="lisp">CL-WAFFE&gt; transpose
</code></pre><pre><code class="lisp">#Const(((-2.36... -1.45... -0.88...)) :dtype :float :shape (1 3) :backward &lt;Node: TRANSPOSETENSOR{W907}&gt;)
</code></pre><p>This property helps to reduce the cost of !transpose before !matmul
</p><p>
</p><p>
</p><h2 id="parameter-and-const">Parameter and Const</h2><p>There are two types of WaffeTensor, parameter and constant. The parameter creates gradient when (backward out) is called, on the other hand, the constant doesn't.
</p><h3 id="initialize-constants">Initialize Constants</h3><p>cl-waffe provides various ways to initialize constants. For example, `!randn` initializes the new tensor of the given dims with sampling the standard distribution, where var=0.0, stdev=1.0. !beta samples the beta distribution with the given alpha and beta.</p><p>
<b>REPL:</b>
</p><pre><code class="lisp">CL-WAFFE&gt; (!randn `(10 10))
</code></pre><pre><code class="lisp">#Const(((-1.20... 0.160... ~ -0.68... 1.776...)        
                 ...
        (0.137... 0.582... ~ 1.254... 0.590...)) :dtype :float :shape (10 10) :backward NIL)
</code></pre><pre><code class="lisp">CL-WAFFE&gt; (!beta `(10 10) 2.0 1.0)
</code></pre><pre><code class="lisp">#Const(((0.787... 0.993... ~ 0.601... 0.962...)        
                 ...
        (0.980... 0.505... ~ 0.553... 0.657...)) :dtype :float :shape (10 10) :backward NIL)
</code></pre><p>WaffeTensors we obtain from standard initializing methods are Constant. In general, cl-waffe provides the constructor (const value). The given value is coerced to properly types. In this example, we obtain mgl-mat from simple-array.</p><p>
<b>REPL:</b>
</p><pre><code class="lisp">CL-WAFFE&gt; (const (make-array `(3 3)))
</code></pre><pre><code class="lisp">#Const(((0.0 0.0 0.0)        
                 ...
        (0.0 0.0 0.0)) :dtype :float :shape (3 3) :backward NIL)
</code></pre><p>
</p><h3 id="initialize-parameter">Initialize Parameter</h3><p>Parameters are initialized via the macro (parameter tensor), which makes the given tensor parameter.</p><p>
<b>REPL:</b>
</p><pre><code class="lisp">CL-WAFFE&gt; (parameter (!randn `(10 10)))
</code></pre><pre><code class="lisp">#Parameter{((-0.41... 0.890... ~ 1.851... -0.73...)            
                         ...
            (-1.29... -1.27... ~ -1.20... -2.28...)) :dtype :float :shape (10 10) :backward NIL}
</code></pre><p>
</p><h3 id="parameter-vs-constant">Parameter vs Constant</h3><p>Excepted Usage of them is:
</p><dl><dt>Constant
</dt><dd>Datasets, the temporary result of calculations, Parameter which is not necessary to be optimized.
</dd><dt>Parameter
</dt><dd>Trainable Variables, to be optimized by <b>optimizers</b> defined by defoptimizer.
</dd></dl><p>
</p><p>
</p><p>
</p>
<h1 id="defnode-and-call">defnode and call</h1><p>
<div class="codex-doc-node codex-operator codex-macro"><code class="codex-name">defnode</code><code class="codex-lambda-list">(name initializer-arguments &amp;key parameters (disassemble-forward nil) forward-declaim forward (disassemble-backward nil) backward-declaim backward (document An node, defined by cl-waffe.))</code><div class="codex-docstring"><p>Defines computation nodes in a format that cl-waffe can handle.</p><p>Note: the data structures that can be used in arguments, and returned values, must be following:</p><ol><li>WaffeTensor</li><li>1D list which each element is WaffeTensor</li></ol><p>Be aware that you can't use (values x y ...).</p><dl><dt>name</dt><dd>The node's name. constructor and structure are being defined named after this argument.</dd><dt>initializer-argument</dt><dd>arguments the constructor have.</dd><dt>parameter</dt><dd>The parameters this node has being initializer with initializer-argument.</dd><dt>disassemble-forward</dt><dd>when t, when this node is compiled, display the disassemble of forward slot.</dd><dt>forward-declaim</dt><dd>Describe the declaim for the forward function. Note that the first argument is a structure. and :forward keyword in this declaim will be replaced by the forward function's name.</dd><dt>forward</dt><dd>the definition of forward</dd><dt>disassemble-backward</dt><dd>when t, when this node is compiled, display the disassemble of backward slot.</dd><dt>backward-declaim</dt><dd>Describe the declaim for the backward function. Note that the first argument is a structure. and :backward keyword in this declaim will be replaced by the backward function's name.</dd><dt>backward</dt><dd>the definition of backward</dd></dl></div></div>
</p><p>The macros <b>defnode</b> and <b>call</b> server as a key component of cl-waffe. In designing deep learning models, incorporating object-oriented programming can lead to more consice descriptions. Although Common Lisp has a powerful framework: CLOS and Closer-MOP, but I think its computational speed strongly depends on what common lisp implementation to use. (e.g.: SBCL/Clozure CL...) Thus, by using only defstruct and defun for defining the computation nodes and wrapping them with macros, (defnode) and (call), I have reduced the overhead associated with the process. This example shows how to define ScalarAdd Node.</p><p>
<b>Input</b>
</p><pre><code class="lisp">CL-WAFFE&gt;
(defnode ScalarAdd ()
  :disassemble-forward t
  :forward-declaim (declaim (ftype (function (ScalarAdd waffetensor waffetensor) waffetensor) :forward))
  :forward ((x y)
	    (let ((x (data x))
		  (y (data y)))
	      (declare (type single-float x y))
	      (const (+ x y))))
  :disassemble-backward t
  :backward-declaim (declaim (type (function (ScalarAdd waffetensor) list) :backward))
  :backward ((dy)(list dy dy)))
</code></pre><b>Output</b><pre><code class="lisp">NIL
</code></pre><p>Through this macro, these structures and functions are defined:
</p><ol><li>The structure, ScalarAdd</li><li>The constructor function, (ScalarAdd)</li><li>The function, (call-scalaradd-forward-mgl self x y) where self is a strucure ScalarAdd</li><li>The function, (call-scalaradd-backward-mgl self dy) where self is a structure ScalarAdd.</li></ol><p>
Setting :disassemble-forward or :disassemble-backward t, prints the disassemble of :forward/:backward (only essential parts) respectively. From the result below, it seems to be optimized enough...
</p><pre><code class="lisp">; disassembly for #:|nodedebug9718|
; Size: 148 bytes. Origin: #x540A110F                         ; #:|nodedebug9718|
; 0F:       498B4510         MOV RAX, [R13+16]                ; thread.binding-stack-pointer
; 13:       488945F8         MOV [RBP-8], RAX
; 17:       4883EC10         SUB RSP, 16
; 1B:       488B55F0         MOV RDX, [RBP-16]
; 1F:       B902000000       MOV ECX, 2
; 24:       48892C24         MOV [RSP], RBP
; 28:       488BEC           MOV RBP, RSP
; 2B:       B802AC3650       MOV EAX, #x5036AC02              ; #&lt;FDEFN DATA&gt;
; 30:       FFD0             CALL RAX
; 32:       480F42E3         CMOVB RSP, RBX
; 36:       4C8BC2           MOV R8, RDX
; 39:       4C8945E0         MOV [RBP-32], R8
; 3D:       4883EC10         SUB RSP, 16
; 41:       488B55E8         MOV RDX, [RBP-24]
; 45:       B902000000       MOV ECX, 2
; 4A:       48892C24         MOV [RSP], RBP
; 4E:       488BEC           MOV RBP, RSP
; 51:       B802AC3650       MOV EAX, #x5036AC02              ; #&lt;FDEFN DATA&gt;
; 56:       FFD0             CALL RAX
; 58:       480F42E3         CMOVB RSP, RBX
; 5C:       4C8B45E0         MOV R8, [RBP-32]
; 60:       4180F819         CMP R8B, 25
; 64:       7538             JNE L1
; 66:       66490F6ED0       MOVQ XMM2, R8
; 6B:       0FC6D2FD         SHUFPS XMM2, XMM2, #4r3331
; 6F:       80FA19           CMP DL, 25
; 72:       7403             JEQ L0
; 74:       CC51             INT3 81                          ; OBJECT-NOT-SINGLE-FLOAT-ERROR
; 76:       08               BYTE #X08                        ; RDX(d)
; 77: L0:   66480F6ECA       MOVQ XMM1, RDX
; 7C:       0FC6C9FD         SHUFPS XMM1, XMM1, #4r3331
; 80:       F30F58CA         ADDSS XMM1, XMM2
; 84:       660F7ECA         MOVD EDX, XMM1
; 88:       48C1E220         SHL RDX, 32
; 8C:       80CA19           OR DL, 25
; 8F:       B902000000       MOV ECX, 2
; 94:       FF7508           PUSH QWORD PTR [RBP+8]
; 97:       B802DD3650       MOV EAX, #x5036DD02              ; #&lt;FDEFN CONST&gt;
; 9C:       FFE0             JMP RAX
; 9E: L1:   CC51             INT3 81                          ; OBJECT-NOT-SINGLE-FLOAT-ERROR
; A0:       20               BYTE #X20                        ; R8(d)
; A1:       CC10             INT3 16                          ; Invalid argument count trap
</code></pre><p>
</p><pre><code class="lisp">; disassembly for #:|nodedebug9739|
; Size: 84 bytes. Origin: #x541BA04C                          ; #:|nodedebug9739|
; 4C:       498B4510         MOV RAX, [R13+16]                ; thread.binding-stack-pointer
; 50:       488945F8         MOV [RBP-8], RAX
; 54:       4D896D28         MOV [R13+40], R13                ; thread.pseudo-atomic-bits
; 58:       498B5558         MOV RDX, [R13+88]                ; thread.cons-tlab
; 5C:       488D4220         LEA RAX, [RDX+32]
; 60:       493B4560         CMP RAX, [R13+96]
; 64:       772E             JNBE L2
; 66:       49894558         MOV [R13+88], RAX                ; thread.cons-tlab
; 6A: L0:   48893A           MOV [RDX], RDI
; 6D:       48897A10         MOV [RDX+16], RDI
; 71:       48C7421817010050 MOV QWORD PTR [RDX+24], #x50000117  ; NIL
; 79:       488D4217         LEA RAX, [RDX+23]
; 7D:       48894208         MOV [RDX+8], RAX
; 81:       80CA07           OR DL, 7
; 84:       4D316D28         XOR [R13+40], R13                ; thread.pseudo-atomic-bits
; 88:       7402             JEQ L1
; 8A:       CC09             INT3 9                           ; pending interrupt trap
; 8C: L1:   488BE5           MOV RSP, RBP
; 8F:       F8               CLC
; 90:       5D               POP RBP
; 91:       C3               RET
; 92:       CC10             INT3 16                          ; Invalid argument count trap
; 94: L2:   6A20             PUSH 32
; 96:       FF142528050050   CALL [#x50000528]                ; #x52A005B0: LIST-ALLOC-TRAMP
; 9D:       5A               POP RDX
; 9E:       EBCA             JMP L0
</code></pre><p>

<div class="codex-doc-node codex-operator codex-macro"><code class="codex-name">call</code><code class="codex-lambda-list">(model &amp;rest inputs &amp;aux (features (model-inlineable-p model)))</code><div class="codex-docstring">calls the given model's forward slot with inputs.</div></div>
</p><p>Nodes which defined by this macro, works as if CLOS class, and they can have :parameters. However, what makes defnode distinct from them is that:</p><p>
<b>REPL:</b>
</p><pre><code class="lisp">CL-WAFFE&gt; (time (call (ScalarAdd)(const 1.0)(const 1.0)))
</code></pre><pre><code class="lisp">#Const(2.0 :dtype SINGLE-FLOAT :backward &lt;Node: SCALARADD{W924}&gt;)
</code></pre><pre><code class="lisp">CL-WAFFE&gt; (time (+ 1.0 1.0))
</code></pre><pre><code class="lisp">2.0
</code></pre><pre><code class="lisp">Evaluation took:
  0.000 seconds of real time
  0.000005 seconds of total run time (0.000005 user, 0.000000 system)
  100.00% CPU
  11,084 processor cycles
  0 bytes consed
</code></pre><p>
</p><pre><code class="lisp">Evaluation took:
  0.000 seconds of real time
  0.000001 seconds of total run time (0.000000 user, 0.000001 system)
  100.00% CPU
  422 processor cycles
  0 bytes consed
</code></pre><p>
Nodes called by the macro <code>(call)</code> are fully inlined, (like CL's inline-generic-function, static-dispatch). Considering ScalarAdd builds computation node in addition to summing up the arguments, these overheads are enough small. Here's how I achieve this behaviour:</p><p>
<b>REPL:</b>
</p><pre><code class="lisp">CL-WAFFE&gt; (macroexpand `(call (ScalarAdd)(const 1.0)(const 1.0)))
</code></pre><pre><code class="lisp">(LOCALLY
 (DECLARE (OPTIMIZE (SPEED 3)(SAFETY 1))
          (INLINE call-scalaradd-forward-mgl))
 (call-scalaradd-forward-mgl (SCALARADD)(CONST 1.0)(CONST 1.0)))
</code></pre><p>The function call-forward-scalaradd-mgl seems to be inlined. This is because <code>(call)</code> can detect the type of node in the compile time. This leads one of the key propeties, <b>easy to optimise</b>. The functions via defnode and call are optimized like:</p><p>
<b>Input</b>
</p><pre><code class="lisp">CL-WAFFE&gt;
(defun sadd (x y)
    (declare (optimize (speed 3)(safety 0))
             (type single-float x y))
        (call (ScalarAdd)(const x)(const y)))
</code></pre><b>Output</b><pre><code class="lisp">SADD
</code></pre><pre><code class="lisp">(disassemble #'sadd)

; disassembly for SADD
; Size: 943 bytes. Origin: #x541AFCAE                         ; SADD
; AFCAE:       488975F0         MOV [RBP-16], RSI
; AFCB2:       4883EC10         SUB RSP, 16
.
.
(Omitted)
</code></pre><p>
We got a large disassembled codes which means: all processes including building computation nodes parts, are correctly inlined. Anyway, the optimization of sadd function is properly working!. Note that the case when the type of given nodes aren't determined in compile time, call behaviours the different from this.</p><p>
<b>Input</b>
</p><pre><code class="lisp">CL-WAFFE&gt;
(let ((node (ScalarAdd)))
    (macroexpand `(call node (const 1.0)(const 1.0))))
</code></pre><b>Output</b><pre><code class="lisp">(LET* ((MODEL NODE)(INPUTS (LIST (CONST 1.0)(CONST 1.0))))
  (IF (TYPEP MODEL 'MODEL-LIST)
      (PROGN
       (SETQ MODEL (NTH (DATA (CAR INPUTS))(MODEL-LIST-MLIST MODEL)))
       (SETQ INPUTS (CDR INPUTS))
       (ASSERT (NOT (TYPEP MODEL 'MODEL-LIST)) NIL
               cl-waffe.call: Assertion failed because model-list can't posses model-list as a element.)))
  (LOCALLY
   (DECLARE (OPTIMIZE (SPEED 3))
            (MAYBE-INLINE CALL-INLINED-FORWARD))
   (APPLY #'CALL-INLINED-FORWARD MODEL INPUTS)))
</code></pre><p>The expanded equation was slightly more complicated. Anyway, the most important part is <code>(APPLY #'CALL-INLINED-FORWARD MODEL INPUTS)</code>. In short, call-inlined-forward is like:
</p><pre><code class="lisp">(defun call-inlined-forwrd (model &amp;rest inputs)
    (typecase model
        (addtensor (call-addtensor-forward-mgl ...))
        (scalaradd (call-scalaradd-forward-mgl ...))
        (T ; ... If this is first trying, Redefine call-inline-forward and try again
        )))
</code></pre><p>
It may be misleading but simultaneously the most simple example. Of course they're inlined. And call-inlined-forward are automatically redefined when:
</p><ol><li>The new backend is defined.</li><li>The node you specified doesn't match any nodes.</li></ol><p>
That is, No need to pay attention to when they are inlined.</p><p>
<b>Input</b>
</p><pre><code class="lisp">CL-WAFFE&gt;(let ((node (ScalarAdd)))
    (time (call node (const 1.0)(const 1.0))))
</code></pre><b>Output</b><pre><code class="lisp">#Const(2.0 :dtype SINGLE-FLOAT :backward &lt;Node: SCALARADD{W926}&gt;)
</code></pre><pre><code class="lisp">Evaluation took:
  0.000 seconds of real time
  0.000005 seconds of total run time (0.000005 user, 0.000000 system)
  100.00% CPU
  10,502 processor cycles
  0 bytes consed
</code></pre><p>
It works the same as the first example, the overhead is enough small.
(P.S.: I was told that it is impossible for SBCL to optimize a CASE of several thousand lines. The assumption is that the more nodes defined in cl-waffe, the less performance we got. In my own benchmarks, I felt it was doing well enough on the second call, but if it is slow, I know how to make it faster.)</p><p>
By the way, defnode's forward slot can require &amp;rest arguments. However, <code>(call)</code> is a macro, so that we can't use apply. Is there no way to call it with &amp;rest arguments? No, <code>get-forward-caller</code> and <code>get-backward-caller</code> is available to get the function object itself. In cl-waffe's implementation, !concatenate requires an &amp;rest arguments.

<div class="codex-doc-node codex-operator codex-macro"><code class="codex-name">get-forward-caller</code><code class="codex-lambda-list">(model)</code><div class="codex-docstring">Returns the given node (model/node/optimizer)'s forward slot, which is callable with funcall/apply.</div></div>
</p><p>
<div class="codex-doc-node codex-operator codex-macro"><code class="codex-name">get-backward-caller</code><code class="codex-lambda-list">(model)</code><div class="codex-docstring">Returns the given node (model/node/optimizer)'s backward slot, which is callable with funcall/apply.</div></div>
</p><pre><code class="lisp">(defun !concatenate (axis &amp;rest tensors)
  (declare (optimize (speed 3))
	   (type fixnum axis))
  (let* ((node (ConcatenateTensorNode axis))
	 (caller (get-forward-caller node)))
    (apply caller node tensors)))
</code></pre><p>
</p>
<h1 id="writing-node-extensions">Writing Node Extensions</h1><p>You may notice that the functions generated by defnode has the suffix, mgl. This indicates the backend cl-waffe uses. (mgl = mgl-mat).</p><p>
If the existing implementation of nodes aren't suitable for your usage, replace them. and cl-waffe provides the ecosystem to manage these additional implementation, I call it backend. For example, you can replace my broadcasting implementation with another fast implementation method. Let's create a double-float version of AddScalar.</p><p>
<b>Input</b>
</p><pre><code class="lisp">CL-WAFFE&gt;
(define-node-extension ScalarAdd
	     :backend :double-float
	     :forward-declaim (declaim (ftype (function (ScalarAdd waffetensor waffetensor) waffetensor) :forward))
	     :forward ((x y)
	    (let ((x (data x))
		  (y (data y)))
	      (declare (type double-float x y))
	      (const (+ x y))))
	     :backward-declaim (declaim (type (function (ScalarAdd waffetensor) list) :backward))
	     :backward ((dy)(list dy dy)))
</code></pre><b>Output</b><pre><code class="lisp">NIL
</code></pre><p>And receive this:
</p><pre><code class="lisp">[INFO] Inlining call-forward... Total Features: 64
To disable this, set cl-waffe:*ignore-inlining-info* t

[INFO] Inlining call-backward... Total Features: 64
To disable this, set cl-waffe:*ignore-inlining-info* t
</code></pre><p>
It's all done. The backends you defined can be switched via (with-backend backend-name &amp;body body) macro. Let's check how call expands it.

<div class="codex-doc-node codex-operator codex-macro"><code class="codex-name">with-backend</code><code class="codex-lambda-list">(backend &amp;body body)</code><div class="codex-docstring"><p>Switches a backend.</p><p>See also: define-node-extension</p></div></div>
</p><p><b>REPL:</b>
</p><pre><code class="lisp">CL-WAFFE&gt; 
(with-backend :double-float
    (macroexpand `(call (ScalarAdd)(const 1.0d0)(const 1.0d0))))
</code></pre><pre><code class="lisp">(LOCALLY
 (DECLARE (OPTIMIZE (SPEED 3)(SAFETY 1))
          (INLINE call-scalaradd-forward-double-float
           call-scalaradd-forward-mgl))
 (CASE *DEFAULT-BACKEND*
   (DOUBLE-FLOAT
    (call-scalaradd-forward-double-float (SCALARADD)(CONST 1.0d0)
                                         (CONST 1.0d0)))
   (MGL (call-scalaradd-forward-mgl (SCALARADD)(CONST 1.0d0)(CONST 1.0d0)))
   (T (call-scalaradd-forward-mgl (SCALARADD)(CONST 1.0d0)(CONST 1.0d0)))))
</code></pre><p>There's an additional case generated, depending on *default-backend*.</p><p>
<b>REPL:</b>
</p><pre><code class="lisp">CL-WAFFE&gt; 
(with-backend :double-float
    (time (call (scalarAdd)(const 1.0d0)(const 1.0d0))))

</code></pre><pre><code class="lisp">#Const(2.0d0 :dtype DOUBLE-FLOAT :backward &lt;Node: SCALARADD{W931}&gt;)
</code></pre><pre><code class="lisp">Evaluation took:
  0.000 seconds of real time
  0.000005 seconds of total run time (0.000005 user, 0.000000 system)
  100.00% CPU
  9,814 processor cycles
  0 bytes consed
</code></pre><p>
Adding new backends is no pain for cl-waffe!
</p>
<h1 id="mnist-example">MNIST Example</h1><p>Using features that I introduced, we can training MLP Model with MNIST Dataset. In practice, more additional features are needed to put it simply: defmodel and deftrainer.
</p><h2 id="defines-your-model">Defines your model</h2><p><b>REPL:</b>
</p><pre><code class="lisp">CL-WAFFE&gt; 
(defmodel MLP (activation)
  :parameters ((layer1   (cl-waffe.nn:denselayer (* 28 28) 512 T activation))
	       (layer2   (cl-waffe.nn:denselayer 512 256 T activation))
	       (layer3   (cl-waffe.nn:linearlayer 256 10 T)))
  :forward ((x)
	    (with-calling-layers x
	      (layer1 x)
 	      (layer2 x)
	      (layer3 x))))
</code></pre><pre><code class="lisp">NIL
</code></pre><pre><code class="lisp">CL-WAFFE&gt; (MLP :relu)
</code></pre><pre><code class="lisp">&lt;Model: MLP{W937}(
    &lt;Model: LAYER1 -&gt; DENSELAYER{W938} ...&gt;
    &lt;Model: LAYER2 -&gt; DENSELAYER{W941} ...&gt;
    &lt;Model: LAYER3 -&gt; LINEARLAYER{W944} ...&gt;
)&gt;
</code></pre><pre><code class="lisp">CL-WAFFE&gt; (with-output-to-string (out)
    (print-model (MLP :relu) out))
</code></pre><pre><code class="lisp">––– &lt;Model MLP{W945}&gt;
––––––– &lt;MLP's LAYER1 = DENSELAYER{W946}&gt;
        |-ACTIVATION-|
        |___RELU_____|
––––––––––– &lt;DENSELAYER's LAYER = LINEARLAYER{W947}&gt;
            |––slot––|–––shape–––|–trainable–|
             WEIGHT -&gt; (784 512)       O
              BIAS  -&gt;  (1 512)        O
––––––– &lt;MLP's LAYER2 = DENSELAYER{W949}&gt;
        |-ACTIVATION-|
        |___RELU_____|
––––––––––– &lt;DENSELAYER's LAYER = LINEARLAYER{W950}&gt;
            |––slot––|–––shape–––|–trainable–|
             WEIGHT -&gt; (512 256)       O
              BIAS  -&gt;  (1 256)        O
––––––– &lt;MLP's LAYER3 = LINEARLAYER{W952}&gt;
        |––slot––|––shape–––|–trainable–|
         WEIGHT -&gt; (256 10)       O
          BIAS  -&gt;  (1 10)        O

 -(+) Total Param: 0
</code></pre><p>
</p><h2 id="define-your-trainer">define your trainer</h2><p><b>REPL:</b>
</p><pre><code class="lisp">CL-WAFFE&gt; 
(deftrainer MLPTrainer (activation lr)
  :model          (MLP activation)
  :optimizer      cl-waffe.optimizers:Adam
  :optimizer-args (:lr lr)
  :step-model ((x y)
	       (zero-grad)
	       (let ((out (cl-waffe.nn:softmax-cross-entropy (call (model) x) y)))
		 (backward out)
		 (update)
		 out))
 :predict ((x)(call (model) x)))
</code></pre><pre><code class="lisp">NIL
</code></pre><pre><code class="lisp">CL-WAFFE&gt; (setq trainer (MLPTrainer :relu 1e-3))
</code></pre><pre><code class="lisp">&lt;Trainer: MLPTRAINER()&gt;
</code></pre><pre><code class="lisp">CL-WAFFE&gt; (slot-value trainer 'cl-waffe::optimizer)
</code></pre><pre><code class="lisp">&lt;Optimizer: ADAM{W965}
    Param: #&lt;GENERAL-HASH-TABLE :TEST EQL :COUNT 6 :WEAKNESS :VALUE {100EAEF273}&gt;
    LR : 0.001
    Param: #&lt;HASH-TABLE :TEST EQL :COUNT 0 {100EAEF363}&gt;
    Param: #&lt;HASH-TABLE :TEST EQL :COUNT 0 {100EAEF403}&gt;
    N : 0
    EPSILON : 1.0e-7
    BETA1 : 0.9
    BETA2 : 0.999
    [Total Param]: 535818
&gt;
</code></pre><p>
(This section is still under progress. However, here's a MLP model which can achive 98% valid_accuracy.)
<a href="https://github.com/hikettei/cl-waffe/blob/main/examples/fnn.lisp">fnn.lisp</a>
If you have cloned the cl-waffe's repository, Lakefile would be available:
</p><pre><code class="shell">$ lake example:install # Install training dataset
$ lake example:mnist # Start training. (batch-size=100)
</code></pre><p>
</p>

      </div>
    </main>
  </article>
  <footer>
    <div class="info">
      Created with <a href="https://github.com/CommonDoc/codex">Codex</a>.
    </div>
  </footer>
  <script>
   HighlightLisp.highlight_auto();
  </script>

  </body>
</html>
